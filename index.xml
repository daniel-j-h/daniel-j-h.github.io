<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniel J. H.</title>
    <link>https://daniel-j-h.github.io/</link>
    <description>Recent content on Daniel J. H.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Dec 2016 20:36:17 +0100</lastBuildDate>
    <atom:link href="https://daniel-j-h.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Strong Typedefs in C&#43;&#43; by Inheriting Constructors</title>
      <link>https://daniel-j-h.github.io/post/strong-typedefs-inheriting-constructors/</link>
      <pubDate>Mon, 12 Dec 2016 20:36:17 +0100</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/strong-typedefs-inheriting-constructors/</guid>
      <description>

&lt;h2 id=&#34;motivation:240ae847aec3a6a4121b5a3eb74dec29&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Suppose we want to represent a &lt;code&gt;Tree&lt;/code&gt; type as either a &lt;code&gt;Leaf&lt;/code&gt; type or a recursive &lt;code&gt;Node&lt;/code&gt; type which holds a left and right &lt;code&gt;Tree&lt;/code&gt; itself.
One way to accomplish this is making use of a type-safe sumtype such as Boost.Variant.
In addition we want our &lt;code&gt;Tree&lt;/code&gt; type to be a strong typedef instead of a weak alias for a variant.&lt;/p&gt;

&lt;p&gt;This can can be done in C++11 and C++14 by inheriting from the variant and then inheriting its constructors, too.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;using TreeBase = boost::variant&amp;lt;Leaf, boost::recursive_wrapper&amp;lt;Node&amp;gt;&amp;gt;;

struct Tree : TreeBase {
  using TreeBase::TreeBase;

  // ...
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our &lt;code&gt;Tree&lt;/code&gt; is now a strong typedef (opaque typedef, newtype). Great!&lt;/p&gt;

&lt;p&gt;Except that GCC trunk crashes with an internal compiler error.
And LLVM rejects this with compile-time errors, too.&lt;/p&gt;

&lt;p&gt;As it turns out inheriting constructors has its quirks and defects for which we need C++17 to fix a total of &lt;em&gt;eight&lt;/em&gt; issues documented here:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0136r1.html&#34;&gt;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0136r1.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Quoting the summary for one of those issues regarding inheriting constructors:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Default arguments are a common mechanism for applying SFINAE to constructors. However, default arguments are not carried over when base class constructors are inherited; instead, an overload set of constructors with various numbers of arguments is created in the derived class. This seems problematic.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we take a look at Boost.Variant (pseudocode below) we see how this is &amp;ldquo;problematic&amp;rdquo;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c++&#34;&gt;struct variant {
  template &amp;lt;typename T&amp;gt;
  variant(const T&amp;amp; t, typename enable_if&amp;lt;is_constructible_from&amp;lt;const T&amp;amp;&amp;gt;::value&amp;gt;::type* = 0) { }

  template &amp;lt;typename T&amp;gt;
  variant(T&amp;amp;&amp;amp; t, typename enable_if&amp;lt;is_constructible_from&amp;lt;T&amp;amp;&amp;amp;&amp;gt;&amp;gt;::type* = 0) { }
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inheriting &lt;code&gt;variant&lt;/code&gt;&amp;rsquo;s constructors now creates multiple constructors in the derived class completely messing with the SFINAE approach, as described in the issue summary.&lt;/p&gt;

&lt;p&gt;And this is where my journey ends.
I really hoped for an easy way to create strong typedefs via inheriting constructors.
But as long as there is no language support for it, it seems like a lost cause.&lt;/p&gt;

&lt;h2 id=&#34;further-reading:240ae847aec3a6a4121b5a3eb74dec29&#34;&gt;Further Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0136r1.html&#34;&gt;Rewording inheriting constructors (core issue 1941 et al)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/boostorg/variant/blob/f739850467d544d51721723d2b606764469f6777/include/boost/variant/variant.hpp#L1757-L1792&#34;&gt;Boost.Variant&amp;rsquo;s Constructors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/daniel-j-h/12c8b7f1c59b5a76c7e75dab38eb06fe#file-crash-cc&#34;&gt;Small Self-Contained Reproducible Example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78767&#34;&gt;GCC ICE Ticket&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://svn.boost.org/trac/boost/ticket/12680&#34;&gt;Boost.Variant Ticket&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;summary:240ae847aec3a6a4121b5a3eb74dec29&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Before C++17 you can not tell if inheriting constructors is possible or not other than by reading the library code.
Thanks to Agustín Bergé who brought this to my attention.&lt;/p&gt;

&lt;p&gt;If you are curious have a look at Haskell&amp;rsquo;s pattern matching or Rust&amp;rsquo;s and Swift&amp;rsquo;s enums.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Selection Algorithms for Graph Partitioning</title>
      <link>https://daniel-j-h.github.io/post/selection-algorithms-for-partitioning/</link>
      <pubDate>Sun, 13 Dec 2015 13:53:51 +0100</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/selection-algorithms-for-partitioning/</guid>
      <description>

&lt;p&gt;In which I optimize a graph partitioner by carefully extracting the algorithm&amp;rsquo;s core requirements and then selecting appropriate C++14 Stdlib algorithms.&lt;/p&gt;

&lt;h2 id=&#34;motivation:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;The following paper introduces a simple yet powerful graph partitioning technique called Inertial Flow.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://sommer.jp/roadseparator.htm&#34;&gt;On Balanced Separators in Road Networks&lt;/a&gt; (doi: &lt;code&gt;10.1007/978-3-319-20086&lt;/code&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The basic idea is this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Sort vertices &amp;ldquo;spatially&amp;rdquo; by a linear combination of their coordinate&amp;rsquo;s latitude and longitude&lt;/li&gt;
&lt;li&gt;Take the first &lt;code&gt;k&lt;/code&gt; nodes forming the sources and the last &lt;code&gt;k&lt;/code&gt; nodes forming the sinks&lt;/li&gt;
&lt;li&gt;Run a single Max-Flow algorithm from sources to sinks and return the corresponding Min-Cut&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Setting the balance parameter &lt;code&gt;k&lt;/code&gt; e.g. to &lt;code&gt;0.25 * |V|&lt;/code&gt; guarantees for a balanced partition, since the disjoint sets have at least &lt;code&gt;k&lt;/code&gt; vertices.
As an optimization you can try different spatial orders, that is visually you rotate a line &lt;code&gt;n&lt;/code&gt; times, run the algorithm and return the best cut.
For partitioning your graph you then recurse on both disjoint vertex sets, until you reach a certain depth or a minimum number of nodes.
That&amp;rsquo;s it. Really, it&amp;rsquo;s that simple and it works surprisingly well!&lt;/p&gt;

&lt;p&gt;Take a look at the following map I generated from dumping the partitioner&amp;rsquo;s graph using &lt;a href=&#34;https://github.com/mapbox/tippecanoe&#34;&gt;tippecanoe&lt;/a&gt; to build  a simplified vector tilesets.&lt;/p&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://api.mapbox.com/styles/v1/danieljh/cii4lhkpn005wb8lzwjj43ipy.html?title=true&amp;access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw#9.658735200693558/52.4992304153767/13.449950544246803/0&#39;&gt;&lt;/iframe&gt;

&lt;p&gt;This is a single algorithm run on Berlin with &lt;code&gt;k = 0.25 * |V|&lt;/code&gt; and a simple spatial order by longitude. The blue points represent the first &lt;code&gt;k&lt;/code&gt; vertices under that spatial order forming the source.
The red points represent the last &lt;code&gt;k&lt;/code&gt; vertices under that spatial order forming the sinks.
Running a single Max-Flow algorithms such as Edmonds–Karp, Push–Relabel or Dinic&amp;rsquo;s algorithm from sources to sinks results in the corresponding Min-Cut that is represented by the black points.&lt;/p&gt;

&lt;h2 id=&#34;deriving-the-spatial-order:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Deriving the Spatial Order&lt;/h2&gt;

&lt;p&gt;The spatial order is derived by a binary function &lt;code&gt;spatially&lt;/code&gt; of two vertices, that compares a linear combination of their coordinate&amp;rsquo;s latitude and longitude.&lt;/p&gt;

&lt;p&gt;The first and last &lt;code&gt;k&lt;/code&gt; vertices can then be determined by using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/sort&#34;&gt;&lt;code&gt;std::sort&lt;/code&gt;&lt;/a&gt; as described in the paper.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sort(begin(vertices), end(vertices), spatially);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then take the first and last &lt;code&gt;k&lt;/code&gt; vertices forming sources and sinks, respectively.
But wait, we can do better: there is no need to sort the vertices in the &amp;ldquo;middle&amp;rdquo;. Let&amp;rsquo;s to less work by using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/partial_sort&#34;&gt;&lt;code&gt;std::partial_sort&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;partial_sort(begin(vertices), begin(vertices) + k, end(vertices), spatially);
partial_sort(rbegin(vertices), rbegin(vertices) + k, rend(vertices), flip(spatially));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This sorts the first &lt;code&gt;k&lt;/code&gt; vertices, and then sorts the last &lt;code&gt;k&lt;/code&gt; vertices with flipped arguments for the binary function (we flip the arguments instead of &lt;code&gt;std::not2&lt;/code&gt; so that the relation is still irreflexive). Great, less work and good enough for our use-case!&lt;/p&gt;

&lt;p&gt;But do we really need a complete ordering of the first and last &lt;code&gt;k&lt;/code&gt; vertices? After all we only need the order to determine sources and sinks for the Max-Flow algorithm.
We are neither interested in which order the first &lt;code&gt;k&lt;/code&gt; are, nor in which order the last &lt;code&gt;k&lt;/code&gt; elements are.
Take a look at the visualization: all what matters is the vertex property &amp;ldquo;first &lt;code&gt;k&lt;/code&gt; in the spatial order&amp;rdquo; (blue) or &amp;ldquo;last &lt;code&gt;k&lt;/code&gt; in the spatial order&amp;rdquo; (red). It does not matter how the red or blue points are ordered in the set of red and blue vertices, respectively.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s give this another try. With &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; we can get the element at position &lt;code&gt;k&lt;/code&gt; that would occur there if the full range was sorted.
In addition, all the elements before the &lt;code&gt;k&lt;/code&gt;th element are &amp;ldquo;less or equal&amp;rdquo; to that element. Interesting, so this is a variation of insertion sort.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nth_element(begin(vertices), begin(vertices) + k, end(vertices), spatially);
nth_element(rbegin(vertices), rbegin(vertices) + k, rend(vertices), flip(spatially));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Visually speaking, this tells us &amp;ldquo;these are red&amp;rdquo;, and &amp;ldquo;these are blue&amp;rdquo;, without any ordering guarantees in the sets.&lt;/p&gt;

&lt;p&gt;It is crucial to understand the difference to partial sorting. Suppose we have a range of integers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;8 7 6 4 5 3 3 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/partial_sort&#34;&gt;&lt;code&gt;std::partial_sort&lt;/code&gt;&lt;/a&gt; on the first and last three elements results in the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2 3 3 _ _ 6 7 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In contrast, using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; on position three from the beginning and end gives you the following guarantees:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_ _ 3 _ _ 6 _ _
____|     |____
&amp;lt;= 3       &amp;gt;= 6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The subranges are no longer sorted, but satisfy the binary function with respect to the selected element. This allows the algorithm to do less work then the partial or even the full sort algorithm.&lt;/p&gt;

&lt;p&gt;Now that we know how &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; works and what guarantees it gives us, we can even go further: the second &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; does not have to take a look at the full range, since we know that we already reordered the first &lt;code&gt;k&lt;/code&gt; elements with the flipped binary function. We therefore come up with the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nth_element(begin(vertices), begin(vertices) + k, end(vertices), spatially);
nth_element(rbegin(vertices), rbegin(vertices) + k, rend(vertices) - k, flip(spatially));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This reorders the first &lt;code&gt;k&lt;/code&gt; elements by looking at the full range and then reorders the last &lt;code&gt;k&lt;/code&gt; elements by only looking at the &lt;code&gt;k + (size - k)&lt;/code&gt; elements from the end.&lt;/p&gt;

&lt;h2 id=&#34;discussion:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Discussion&lt;/h2&gt;

&lt;p&gt;I talked to Christian Sommer, one of the paper&amp;rsquo;s authors, about this. He acknowledged there is no need for a full ordering that &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/sort&#34;&gt;&lt;code&gt;std::sort&lt;/code&gt;&lt;/a&gt; gives you as described in the paper.
Furthermore he argued that you could fully sort your &lt;code&gt;n&lt;/code&gt; spatial orders and keep them around for all recursion steps, which would require more memory and algorithms that can select the subgraph&amp;rsquo;s vertices from the orders.&lt;/p&gt;

&lt;p&gt;As of writing this, the prototype partitioner still uses the Edmonds-Karp algorithms.
We can probably gain significant improvements by using Dinic&amp;rsquo;s algorithm, shadowing the small improvements achieved here.
This does not mean that we should not optimize for easy wins as it was with this case; after all the final reordering optimization on its own is faster than a full sort by a factor of 4-7 from what I saw in a few experiments.
Also, this is where the fun is in engineering and programming :-)&lt;/p&gt;

&lt;h2 id=&#34;further-reading:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Further Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Sean Parent &lt;a href=&#34;https://github.com/sean-parent/sean-parent.github.io/wiki/Papers-and-Presentations&#34;&gt;has a few papers and presentations&lt;/a&gt; in which he explains similar clever Stdlib algorithm usage&lt;/li&gt;
&lt;li&gt;Alexander Stepanov&amp;rsquo;s &amp;ldquo;From Mathematics to Generic Programming&amp;rdquo; and &amp;ldquo;Elements of Programming&amp;rdquo; go in great detail about algorithm requirements and guarantees&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;summary:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Inertial Flow is a simple yet powerful graph partitioning technique that requires a spatial order.
Deriving the spatial order can be optimized by carefully looking at the algorithm&amp;rsquo;s requirements.
Know your Stdlib, in particular be familiar with more &amp;ldquo;exotic&amp;rdquo; algorithms such as &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/rotate&#34;&gt;&lt;code&gt;std::rotate&lt;/code&gt;&lt;/a&gt; &amp;mdash; or of course equivalent algorithms in your language of choice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LaTeX A Modern Approach</title>
      <link>https://daniel-j-h.github.io/post/latex-a-modern-approach/</link>
      <pubDate>Sun, 14 Jun 2015 21:53:57 +0200</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/latex-a-modern-approach/</guid>
      <description>

&lt;p&gt;In which I fight my way through decades of legacy and bad habits to find beauty in producing documents with LaTeX.&lt;/p&gt;

&lt;h2 id=&#34;motivation:48174f4215bbd58febb4c58acfc25505&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;LaTeX is a pain to get started with, not only but mainly because of its legacy going back several decades.
Then, you may ask, why do I still prefer it over LibreOffice, Word, you name it?
There are compelling reasons ranging from proper kerning to small caps and old style figures.
In short: it is still the only viable option for producing visually pleasing documents.
For graphical side-by-side comparisons of what this means take a look &lt;a href=&#34;http://nitens.org/taraborelli/latex&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://www.zinktypografie.nl/latex.php?lang=en&#34;&gt;here&lt;/a&gt;.
In the following I&amp;rsquo;m going to show you important tricks and hints that helped me find beauty in producing documents with a modern LaTeX approach.&lt;/p&gt;

&lt;p&gt;I assume you are somewhat familiar with LaTeX basics.
If not, course materials are available &lt;a href=&#34;http://liinwww.ira.uka.de/~thw/vl-latex-co/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.sharelatex.com/learn&#34;&gt;ShareLaTeX&lt;/a&gt; is also quite good.&lt;/p&gt;

&lt;h2 id=&#34;building-latex-documents:48174f4215bbd58febb4c58acfc25505&#34;&gt;Building LaTex Documents&lt;/h2&gt;

&lt;p&gt;To compile a LaTeX document, you invoke the engine The Right Amount Of Times &amp;trade;.
Then bibtex for generating references.
Then the LaTeX engine multiple times again to adapt the layout to the inserted references.&lt;/p&gt;

&lt;p&gt;Wat? There has to be a better way. And there is!&lt;/p&gt;

&lt;h3 id=&#34;latexmk:48174f4215bbd58febb4c58acfc25505&#34;&gt;latexmk&lt;/h3&gt;

&lt;p&gt;Introducing &lt;a href=&#34;https://www.ctan.org/pkg/latexmk/?lang=en&#34;&gt;latexmk&lt;/a&gt;:
latexmk is similar to make and knows how often and in which order to run the engine and bibtex.
It is even able to generate external resources by invoking a makefile itself.
I recommend you to take a look at its documentation, as it can be used to fully replace a makefile, with options to wait on changes, trigger rebuilds, and more.&lt;/p&gt;

&lt;p&gt;I came to the conclusion that wrapping latexmk in a makefile is still beneficial.
Take a look at what my typical LaTeX makefile looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;engine=&amp;quot;lualatex -interactive=nonstopmode --shell-escape %O %S&amp;quot;
refs = bibliography.bib
sources = main.tex chapters/some-chapters.tex

main.pdf: $(sources)
	@latexmk -pdf -pdflatex=${engine} -bibtex $&amp;lt;

watch:
	@while ! inotifywait --event modify $(refs) $(sources); do make; done

spell:
	@hunspell -l -t -d en_US -i utf-8 $(sources) | sort | uniq --ignore-case

clean:
	@latexmk -C

.PHONY: watch spell clean
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This provides you with several targets:
While &lt;code&gt;make&lt;/code&gt; builds the document once &lt;code&gt;make watch&lt;/code&gt; listens on modifications to your sources and builds the document.
This allows you to keep your document viewer open and get a updated document every time you save your source.
&lt;code&gt;make spell&lt;/code&gt; spell checks your sources with hunspell and understands the LaTeX syntax to some degree and &lt;code&gt;make clean&lt;/code&gt; delegates to latexmk for removing temporary build files (you probably need to remove some files in addition).&lt;/p&gt;

&lt;h3 id=&#34;lualatex:48174f4215bbd58febb4c58acfc25505&#34;&gt;lualatex&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;m using &lt;code&gt;lualatex&lt;/code&gt; as an engine.
You may want to replace it with &lt;code&gt;pdflatex&lt;/code&gt; or &lt;code&gt;xelatex&lt;/code&gt; if you prefer those.
I found &lt;code&gt;lualatex&lt;/code&gt; the only viable engine for basically two reasons:
one, it is actively maintained and designed with a modern approach in mind (support for unicode, system fonts, etc.) and two, it does not have ridiculous memory constraints that you easily reach e.g. when plotting charts.&lt;/p&gt;

&lt;p&gt;The only downside in using &lt;code&gt;lualatex&lt;/code&gt; I found is an increase in build times.
This is a bit frustrating for when using the &lt;code&gt;make watch&lt;/code&gt; target and then having to wait multiple seconds until the document gets refreshed in the viewer.&lt;/p&gt;

&lt;p&gt;Read the &lt;a href=&#34;https://www.ctan.org/pkg/lualatex-doc?lang=en&#34;&gt;lualatex documentation&lt;/a&gt; if you want to make the switch.
Also note that switching to &lt;code&gt;lualatex&lt;/code&gt; is not just replacing the engine; you need to switch out a few packages &amp;mdash; but all this is documented and is rather easy to do.&lt;/p&gt;

&lt;p&gt;In the following I&amp;rsquo;m assuming you are using &lt;code&gt;lualatex&lt;/code&gt; as an engine.
Now that we can build documents let&amp;rsquo;s take a look at how to design them!&lt;/p&gt;

&lt;h2 id=&#34;designing-the-document:48174f4215bbd58febb4c58acfc25505&#34;&gt;Designing The Document&lt;/h2&gt;

&lt;p&gt;In the following I&amp;rsquo;m going to show you how to design your document in a modern approach, making use of some awesome packages.&lt;/p&gt;

&lt;h3 id=&#34;document-classes:48174f4215bbd58febb4c58acfc25505&#34;&gt;Document Classes&lt;/h3&gt;

&lt;p&gt;Document classes describe the document&amp;rsquo;s purpose: is it a book, a report or even a letter?
Unfortunately, there is almost no case for using the ones LaTeX comes with.
Instead I recommend the KOMA-Script bundle, that includes modern replacements for LaTeX own document classes.
As usual the &lt;a href=&#34;https://www.ctan.org/pkg/koma-script?lang=en&#34;&gt;koma-script documentation&lt;/a&gt; is superb &amp;mdash; read it!&lt;/p&gt;

&lt;p&gt;Switching to the KOMA-Script document classes is as easy as changing your preamble to something along the lines of:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\documentclass[draft=false
             , BCOR=0mm  % correct binding offset when printing
             , 12pt
             , headings=big
             , chapterprefix=true
             , numbers=noenddot]{scrreprt}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;warnings:48174f4215bbd58febb4c58acfc25505&#34;&gt;Warnings&lt;/h3&gt;

&lt;p&gt;There is a package that you should include first: &lt;a href=&#34;https://www.ctan.org/pkg/nag&#34;&gt;nag&lt;/a&gt;.
Why first? Because it warns you about obsolete commands and package.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage[l2tabu,orthodox]{nag}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;typography:48174f4215bbd58febb4c58acfc25505&#34;&gt;Typography&lt;/h3&gt;

&lt;p&gt;If you have the time and interest I really recommend you getting &lt;a href=&#34;http://www.goodreads.com/book/show/44735.The_Elements_of_Typographic_Style&#34;&gt;The Elements of Typographic Style&lt;/a&gt;.
A quick introduction is at &lt;a href=&#34;http://practicaltypography.com/&#34;&gt;Butterick&amp;rsquo;s Practical Typography&lt;/a&gt; that is quite good but also opinionated to some degree.&lt;/p&gt;

&lt;p&gt;For anything font-related I recommend &lt;a href=&#34;https://www.ctan.org/pkg/fontspec?lang=en&#34;&gt;fontspec&lt;/a&gt;.
And for improving details you had no idea about, take a look at &lt;a href=&#34;https://www.ctan.org/pkg/microtype&#34;&gt;microtype&lt;/a&gt; (with the most beautifully looking documentation)!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{fontspec}
\usepackage{microtype}
\frenchspacing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;\frenchspacing&lt;/code&gt; disables two spaces after a dot, which is what you normally want.
Also read the documentation before adding options; microtype for example is smart enough to do its best in selecting options depending on engine and environment.
In determining which fonts are getting used the &lt;code&gt;pdffonts&lt;/code&gt; tool from the &lt;code&gt;poppler-utils&lt;/code&gt; package is quite helpful.&lt;/p&gt;

&lt;p&gt;Latin Modern is a good default, but I wanted to use &lt;a href=&#34;https://en.wikipedia.org/wiki/Palatino&#34;&gt;Hermann Zapf&amp;rsquo;s Palatino&lt;/a&gt; as main font.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Now is the right time to watch &lt;a href=&#34;https://www.youtube.com/watch?v=3jD4CpzIuR4&#34;&gt;The Art Of Hermann Zapf&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Most good looking fonts that include small caps, old style figures and more, you have to pay for.
Fortunately there is the &lt;a href=&#34;http://www.gust.org.pl/projects/e-foundry/tex-gyre&#34;&gt;TeX Gyre&lt;/a&gt; project that includes a Palatino remake with &lt;code&gt;TeX Gyre Pagella&lt;/code&gt;.
In case you make use of math symbols there is also the recent &lt;a href=&#34;http://www.gust.org.pl/projects/e-foundry/tg-math/index_html&#34;&gt;TeX Gyre Math&lt;/a&gt; project.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{unicode-math}
\setmainfont[Ligatures=TeX, Numbers=OldStyle]{TeX Gyre Pagella}
\setmathfont{TeX Gyre Pagella Math}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;TeX ligatures are e.g. for enabling en-dash and em-dash ligatures.
On a related note, learn the difference between a hyphen -, the en-dash &amp;ndash; and the em-dash &amp;mdash;!
Also note that Pagella&amp;rsquo;s ligatures &lt;a href=&#34;http://tex.stackexchange.com/a/94411&#34;&gt;are ligatures but do not look as fused as in other fonts&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After some research I found sans and mono fonts (that can be scaled automatically to the main font) beautifully matching Palatino:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\setsansfont[Scale=MatchLowercase]{Bitstream Vera Sans}
\setmonofont[Scale=MatchLowercase]{Inconsolata}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, KOMA-Script sets dispositions like &lt;code&gt;\section&lt;/code&gt; in bold sans by default.
In my opinion the switch from the main text&amp;rsquo;s serif font to bold sans is quite distracting.
Instead I&amp;rsquo;m using serif small caps for dispositions (and the page header) that are not bold by default:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\addtokomafont{disposition}{\rmfamily}
\setkomafont{pagehead}{\scshape}
\setkomafont{disposition}{\scshape}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;language:48174f4215bbd58febb4c58acfc25505&#34;&gt;Language&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;lualatex&lt;/code&gt; works well together with &lt;code&gt;polyglossia&lt;/code&gt; &amp;mdash; use it instead of babel:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{polyglossia}
\setdefaultlanguage{english}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;tables:48174f4215bbd58febb4c58acfc25505&#34;&gt;Tables&lt;/h3&gt;

&lt;p&gt;I found &lt;a href=&#34;https://www.ctan.org/pkg/booktabs?lang=en&#34;&gt;booktabs&lt;/a&gt; to produce professional looking tables.
Its documentation also gives great hints how to design your table:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{booktabs}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;colors:48174f4215bbd58febb4c58acfc25505&#34;&gt;Colors&lt;/h3&gt;

&lt;p&gt;I highly recommend using &lt;a href=&#34;http://colorbrewer2.org/&#34;&gt;ColorBrewer&lt;/a&gt; for selecting an appropriate color palette:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{xcolor}

\definecolor{primary}{RGB}{117,112,179}
\definecolor{secondary}{RGB}{27,158,119}
\definecolor{tertiary}{RGB}{217,95,2}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;source-code:48174f4215bbd58febb4c58acfc25505&#34;&gt;Source Code&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;https://www.ctan.org/pkg/minted?lang=en&#34;&gt;minted&lt;/a&gt; package makes use of &lt;a href=&#34;http://pygments.org/&#34;&gt;Pygments&lt;/a&gt; for syntax highlighting.
This approach is by far more robust than other listings packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{minted}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not to sound like a perfectionist, but there is a way to &lt;a href=&#34;http://pygments.org/docs/styles/#creating-own-styles&#34;&gt;adapt the color scheme to your document&amp;rsquo;s color palette&lt;/a&gt;.
Using the color scheme requires creating and then registering your plugin, which is quite a bit effort.&lt;/p&gt;

&lt;h3 id=&#34;plots:48174f4215bbd58febb4c58acfc25505&#34;&gt;Plots&lt;/h3&gt;

&lt;p&gt;I came to the conclusion that native LaTeX graphics just look the best.
For this I&amp;rsquo;m using &lt;a href=&#34;https://www.ctan.org/pkg/pgfplots?lang=en&#34;&gt;pgfplots&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What I&amp;rsquo;m doing is the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;save my experiment&amp;rsquo;s data in an interchangable format, e.g. csv&lt;/li&gt;
&lt;li&gt;load and analyze the data, e.g. with Pandas (save scripts for reproducibility)&lt;/li&gt;
&lt;li&gt;save the processed data in a format that pgfplot understands&lt;/li&gt;
&lt;li&gt;use pgfplots to create beautiful plots&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This works great for plot types that are supported by pgfplots (quite a large number, skim the documentation).
I also recommend using the &lt;a href=&#34;https://www.ctan.org/pkg/units?lang=en&#34;&gt;units&lt;/a&gt; package in addition and setting some sane defaults globally:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{tikz}
\usepackage{pgfplots}
\usepgfplotslibrary{units}
\SendSettingsToPgf
\usepgfplotslibrary{statistics}

\pgfplotscreateplotcyclelist{colorscheme}{{primary},{secondary},{tertiary}}

\pgfplotsset{compat=1.11
           , tick label style = {font=\tiny}
	   , % etc.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the following I will show you how to produce a few beautiful looking plots, with negative space as a design decision.
The general idea is to wrap your plot in a figure with &lt;code&gt;htb&lt;/code&gt; as placement constraint, i.e. place here, top or bottom but never on a separate page.
In addition you want a caption and a label for all your plots.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \begin{axis}[options]
      % plot specifics
    \end{axis}
  \end{tikzpicture}
  \caption{My caption}
  \label{fig: my-figure}
\end{figure}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For printing I keep a separate black and white color palette around, as it is hard to find one that is very good for both scenarios. In the following I&amp;rsquo;m using the color palette from above.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Consult &lt;a href=&#34;http://www.goodreads.com/book/show/17745.Envisioning_Information&#34;&gt;Envisioning Information&lt;/a&gt; and &lt;a href=&#34;http://www.goodreads.com/book/show/17744.The_Visual_Display_of_Quantitative_Information&#34;&gt;The Visual Display of Quantitative Information&lt;/a&gt; on visual data representation&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;boxplot:48174f4215bbd58febb4c58acfc25505&#34;&gt;Boxplot&lt;/h4&gt;

&lt;p&gt;Here&amp;rsquo;s an example for a boxplot as wide as the main text&amp;rsquo;s flow and its height respecting the golden ratio for a visually pleasing aspect ratio.
The box&amp;rsquo;s width are also proportional to the group&amp;rsquo;s sizes &amp;mdash; this has to be calculated externally:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\begin{axis}[width=\textwidth
           , height=0.618\textwidth % golden ratio
           , boxplot/draw direction=y
           , xlabel={year}
           , ylabel={sleepiness}
           , ymin=0, ymax=1
           , xtick={1,2,3,4,5,6,7}
           , xticklabels={2009, 2010, 2011, 2012, 2013, 2014, 2015}
           , enlargelimits=0
           , enlarge x limits]
  % box extend is calculated as sqrt(group&#39;s size) normalized to [0,1], expressing sample size in boxplot
  \addplot+[boxplot, box extend=0.869] table[row sep=newline,y index=0]{data/boxplot-2009.csv};
  \addplot+[boxplot, box extend=0.869] table[row sep=newline,y index=0]{data/boxplot-2010.csv};
  \addplot+[boxplot, box extend=0.865] table[row sep=newline,y index=0]{data/boxplot-2011.csv};
  \addplot+[boxplot, box extend=1.000] table[row sep=newline,y index=0]{data/boxplot-2012.csv};
  \addplot+[boxplot, box extend=0.478] table[row sep=newline,y index=0]{data/boxplot-2013.csv};
  \addplot+[boxplot, box extend=0.307] table[row sep=newline,y index=0]{data/boxplot-2014.csv};
  \addplot+[boxplot, box extend=0.517] table[row sep=newline,y index=0]{data/boxplot-2015.csv};
\end{axis}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://daniel-j-h.github.io/images/latex-a-modern-approach/pgfplots-boxplot.png&#34; alt=&#34;Boxplot generated with pgfplots&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;lineplot:48174f4215bbd58febb4c58acfc25505&#34;&gt;Lineplot&lt;/h4&gt;

&lt;p&gt;Here&amp;rsquo;s a trend plot, now only constraining the height to be equal to the golden ratio respecting plots:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\begin{axis}[height=0.681\textwidth,
           , xlabel={elapsed time}
           , ylabel={coffee intake}
           , x unit=\si{\second}
           , y unit=\si{\liter}
           , xmin=0,xmax=30
           , ymin=0,ymax=400
           , smooth]
  \addplot table[x=elapsed,y=intake,col sep=comma]{data/coffee-deadline.csv}; \addlegendentry{deadline};
  \addplot table[x=elapsed,y=intake,col sep=comma]{data/coffee-normal.csv}; \addlegendentry{normal};
\end{axis}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://daniel-j-h.github.io/images/latex-a-modern-approach/pgfplots-lineplot.png&#34; alt=&#34;Lineplot generated with pgfplots&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;barplot:48174f4215bbd58febb4c58acfc25505&#34;&gt;Barplot&lt;/h4&gt;

&lt;p&gt;And finally a barplot, with the trick of grid lines that are on top and of the same color as the background, as recommended by Edward Tufte:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\begin{axis}[height=0.681\textwidth
           , ybar
           , xlabel={time to deadline}
           , ylabel={calorie intake}
           , x unit=\si{\second}
           , y unit=\si{\joule}
           , change y base
           , y SI prefix=kilo
           , ymajorgrids=true
           , axis on top
           , grid style=white
           , major tick length=0pt
           , ymin=0
           , xtick=data
         ]
  \addplot+[draw opacity=0] table[x=time,y=intake,col sep=comma]{data/intake-food.csv}; \addlegendentry{food}
  \addplot+[draw opacity=0] table[x=time,y=intake,col sep=comma]{data/intake-coffee.csv}; \addlegendentry{coffee}
  \addplot+[draw opacity=0] table[x=time,y=intake,col sep=comma]{data/intake-overall.csv}; \addlegendentry{overall}
\end{axis}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://daniel-j-h.github.io/images/latex-a-modern-approach/pgfplots-barplot.png&#34; alt=&#34;Stacked plot generated with pgfplots&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;references:48174f4215bbd58febb4c58acfc25505&#34;&gt;References&lt;/h3&gt;

&lt;p&gt;I found Biber to be great as a modern BibTeX replacement.
There are a few tricks required, e.g. for proper quotes in the references, otherwise it Just Works &amp;trade;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage[strict=true]{csquotes}
\usepackage[backend=biber
          , bibencoding=utf-8
          , safeinputenc
          , bibwarn=true
          , style=alphabetic
          , doi=false
          , isbn=false
          , url=false]{biblatex}
\addbibresource{bibliography.bib}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scaling:48174f4215bbd58febb4c58acfc25505&#34;&gt;Scaling&lt;/h3&gt;

&lt;p&gt;The last trick is to disable print scaling, otherwise your document may be scaled and you absolutely do not want this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\usepackage{hyperref}
\hypersetup{pdfauthor={My Name}
          , pdftitle={My Title}
          , pdfprintscaling=None}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;markdown:48174f4215bbd58febb4c58acfc25505&#34;&gt;Markdown&lt;/h3&gt;

&lt;p&gt;There is a trick that I&amp;rsquo;m using for writing down notes in markdown and producing a pdf from it.
It&amp;rsquo;s the awesome &lt;a href=&#34;http://pandoc.org/&#34;&gt;pandoc&lt;/a&gt; tool that is able to convert between a ridiculous amount of formats.
For this I have a makefile with a target similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pandoc --filter=pandoc-citeproc --bibliography=$(ref) --toc --latex-engine=$(engine) -o $(target) $(src)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;inspiration:48174f4215bbd58febb4c58acfc25505&#34;&gt;Inspiration&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://vimeo.com/45232468&#34;&gt;Inge Druckrey: Teaching to See&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Satisfiability Modulo Theories For Parallel Cooking And Other Optimizations</title>
      <link>https://daniel-j-h.github.io/post/satisfiability-modulo-theories-for-parallel-cooking-and-other-optimizations/</link>
      <pubDate>Fri, 08 May 2015 20:34:36 +0200</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/satisfiability-modulo-theories-for-parallel-cooking-and-other-optimizations/</guid>
      <description>

&lt;p&gt;Using an optimizing constraint solver to answer fundamental questions, such as &amp;ldquo;How to optimize parallel Pizza cooking&amp;rdquo;, and &amp;ldquo;How to optimize layouting in CSS&amp;rdquo;.
In this article I will not only give answers to those questions but you will also get an introduction into Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) solvers &amp;ndash; Z3 in particular.&lt;/p&gt;

&lt;h2 id=&#34;motivation:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Another week, another newly open sourced project to play with!
This time it is the &lt;a href=&#34;https://github.com/Z3Prover/z3&#34;&gt;Z3 Theorem Prover&lt;/a&gt; that I want to have fun with.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s get you started with the basics required for understanding the examples (read: you can skip till the &amp;ldquo;Parallel Cooking&amp;rdquo; section if you want code now).&lt;/p&gt;

&lt;h2 id=&#34;satisfiability:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Satisfiability&lt;/h2&gt;

&lt;p&gt;Suppose we have a formula consisting of the &lt;em&gt;literals&lt;/em&gt; A, B, C and a conjunction of two &lt;em&gt;clauses&lt;/em&gt;, i.e. a formula in Conjunctive Normal Form (CNF):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(A or C) and (not B)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Is there an assignment for the literals A, B and C to make the formula true?
Sure, I can come up with an assignment:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{A: false, B: false, C: true}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Can you think of another one?&lt;/p&gt;

&lt;p&gt;In general, this is the problem of satisfiability (SAT) which is NP-complete (read: hard).
There are so called SAT-solvers that help us determine if such an assignment exists.
Most if not all SAT-solvers work with the DIMACS format that standardizes how to encode the formula.
The syntax is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c Comment
p cnf numberOfLiterals numberOfClauses
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What follows after the p-line is a way to encode your formula:
literals are numbered starting from one.
A negative number means negation.
The zero at the end of the clause is a line terminator.&lt;/p&gt;

&lt;p&gt;Our formula from above has three &lt;em&gt;literals&lt;/em&gt; (A, B, C) and two &lt;em&gt;clauses&lt;/em&gt; ((A or C), (not B)), the first clause consists of A (1), C (3), the second clause consists of not B (-2):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c this is a dimacs file
p cnf 3 2
1 3 0
-2 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s feed this into Z3 and see what it comes up with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sat
1 -2 -3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which translates to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;{A: true, B: false, C: false}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is an assignment for you: encode this into the DIMACS format and check for satisfiability:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;(A or B) and ((not B) or C or (not D)) and (D or (not E))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s go on with building abstraction on top of SAT solvers, because this can&amp;rsquo;t be it!&lt;/p&gt;

&lt;h2 id=&#34;satisfiability-modulo-theories:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Satisfiability Modulo Theories&lt;/h2&gt;

&lt;p&gt;Now that we can encode problems for SAT solvers you may think:
&amp;ldquo;I can encode integers as boolean literals (read: in binary), much as my computer does it&amp;rdquo; and this is exactly what Satisfiability Modulo Theories (SMT) is all about:
an abstraction on top of SAT, that &amp;ldquo;knows&amp;rdquo; about so called theories.
Let&amp;rsquo;s take a look at some theories and &lt;a href=&#34;http://smtlib.cs.uiowa.edu/theories.shtml&#34;&gt;their documentation&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://smtlib.cs.uiowa.edu/theories/Ints.smt2&#34;&gt;Theory of Integers&lt;/a&gt;: mathematical integers, not machine type&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://smtlib.cs.uiowa.edu/theories/Reals.smt2&#34;&gt;Theory of Reals&lt;/a&gt;: mathematical reals, not machine type&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://smtlib.cs.uiowa.edu/theories/FixedSizeBitVectors.smt2&#34;&gt;Theory of Bitvectors&lt;/a&gt;: vector of bits, for signed and unsigned two&amp;rsquo;s-complement calculations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition, SMT also &amp;ldquo;knows&amp;rdquo; about their rules, e.g. how to add two 32 bit unsigned integers represented as so called Bitvectors.
This takes away the burden to manually implement unsigned addition for 32 boolean literals representing an integer in SAT.&lt;/p&gt;

&lt;p&gt;As with the DIMACS format for SAT, there is a standardized format for SMT, the &lt;a href=&#34;http://smtlib.cs.uiowa.edu/language.shtml&#34;&gt;SMT-LIB 2.0 format&lt;/a&gt;.
It may look rather Lisp&amp;rsquo;ish &amp;ndash; but don&amp;rsquo;t despair, it&amp;rsquo;s still easy to understand (if not, learn yourself some Clojure for great good &amp;ndash; or use Z3&amp;rsquo;s language bindings, e.g. the Python one).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see if we can find an assignment for two integers, satisfying the constraints that x is ten and y should be greater than zero and less then ten:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(set-option :produce-models true)
(set-logic QF_LIA)

(declare-fun x () Int)
(declare-fun y () Int)

(assert (= x 10))
(assert (&amp;lt; 0 y 10))

(check-sat)

(get-value (x))
(get-value (y))

(exit)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is a good idea take a look at the &lt;a href=&#34;http://smtlib.cs.uiowa.edu/language.shtml&#34;&gt;SMT-LIB 2.0 language specification&lt;/a&gt;, where its syntax is specified in Backus-Naur Form.
For our example we have to enable model generation, otherwise the solver only tells us &amp;ldquo;sat&amp;rdquo; or &amp;ldquo;unsat&amp;rdquo;.
We also have to set the &lt;a href=&#34;http://smtlib.cs.uiowa.edu/logics.shtml&#34;&gt;logic&lt;/a&gt; to only use unquantified linear integer arithmetic formulas. Finally we have to express constants as functions that take no arguments.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see what Z3 comes up with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sat
((x 10))
((y 1))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Cool!
But wait, this only gives us a single solution or simply tells us &amp;ldquo;unsat&amp;rdquo;.
What if we want an &amp;ldquo;optimal&amp;rdquo; solution (for our understanding of optimal) under certain constraints?&lt;/p&gt;

&lt;h2 id=&#34;an-optimizing-smt-solver:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;An Optimizing SMT Solver&lt;/h2&gt;

&lt;p&gt;Z3&amp;rsquo;s opt branch implements an optimizing SMT solver, called nuZ.
You can learn more about it in these two papers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/en-US/people/nbjorner/nuz.pdf&#34;&gt;nuZ - An Optimizing SMT Solver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/en-US/people/nbjorner/scss2014.pdf&#34;&gt;nuZ - Maximal Satisfaction with Z3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What follows is strictly speaking not SMT-LIB 2.0 conforming, as there is no syntax for optimization in the specification. The following examples make use of Z3 extensions not only for optimization but also to shorten the amount of boilerplate we have to write, e.g. in creating constants. See &lt;a href=&#34;http://rise4fun.com/Z3/tutorial/guide&#34;&gt;Z3&amp;rsquo;s tutorial&lt;/a&gt; for a quick introduction.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with an example:
we want to maximize the sum of two integers under the constraints that the integer&amp;rsquo;s values should be between or equal to zero and ten:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(declare-const x Int)
(declare-const y Int)

(assert (&amp;lt;= 0 x 10))
(assert (&amp;lt;= 0 y 10))

(maximize (+ x y))

(check-sat)
(get-model)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Feeding this to Z3 gives us an optimal solution, maximizing the sum and also producing a model, showing x and y:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(+ x y) |-&amp;gt; 20
sat
(model
  (define-fun y () Int 10)
  (define-fun x () Int 10))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! This is good enough for now, let&amp;rsquo;s optimize something!&lt;/p&gt;

&lt;h2 id=&#34;parallel-cooking:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Parallel Cooking&lt;/h2&gt;

&lt;p&gt;Say you want to cook Pizza. With multiple cooks. In parallel.
Can we come up with a schedule that minimizes the overall time it takes, while repecting constraints such as &amp;ldquo;We have to slice onions before putting the Pizza into the oven&amp;rdquo;?&lt;/p&gt;

&lt;p&gt;Instead of working only with integers let&amp;rsquo;s create an interval type that abstracts, well, an interval:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(declare-datatypes (BeginT EndT) ((IntervalT (makeInterval (begin BeginT) (end EndT)))))
(define-sort Interval () (IntervalT Int Int))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now created an interval type (what is called Sort by the SMT people) with constructor &lt;em&gt;makeInterval&lt;/em&gt;, and  &lt;em&gt;begin&lt;/em&gt; and &lt;em&gt;end&lt;/em&gt; accessors. For the exact syntax you may take a look at &lt;a href=&#34;http://rise4fun.com/Z3/tutorial/guide&#34;&gt;Z3&amp;rsquo;s datatypes documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s tell Z3 more about intervals.
Valid intervals expand into the future, and have a duration.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(define-fun intervalValid? ((interval Interval)) (Bool)
  (&amp;lt; (begin interval) (end interval)))

(define-fun intervalDuration ((interval Interval)) (Int)
  (- (end interval) (begin interval)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If an interval requires a second interval to be completed, this can also be expressed (to specify dependencies).
The same goes for the requirement of an interval being during a second interval:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(define-fun intervalStartsAfterInterval? ((lhs Interval) (rhs Interval)) (Bool)
  (&amp;gt; (begin lhs) (end rhs)))

(define-fun intervalDuringInterval? ((lhs Interval) (rhs Interval)) (Bool)
  (and
    (&amp;gt; (begin lhs) (begin rhs))
    (&amp;lt; (end lhs) (end rhs))))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s create an overall schedule its duration we want to minimize in the end.
And also create intervals for tasks such as making the dough, slicing onions, slicing tomatos, and so on:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(declare-const schedule Interval)

(declare-const makeDough Interval)
(declare-const sliceOnions Interval)
(declare-const sliceTomatos Interval)
(declare-const bakeInOven Interval)
(declare-const servePizza Interval)
(declare-const pourWine Interval)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now for the constraints, this is where we tell Z3 what properties we require in a solution.
Here we tell Z3 that our schedule starts at time zero, intervals do not go back in time, our tasks should fall into the overall schedule, estimated durations for the tasks and finally the task&amp;rsquo;s dependencies;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(assert (and
          (= 0 (begin schedule))
          (intervalValid? schedule)
 
          (intervalValid? makeDough)
          (intervalValid? sliceOnions)
          (intervalValid? sliceTomatos)
          (intervalValid? bakeInOven)
          (intervalValid? servePizza)
          (intervalValid? pourWine)
 
          (intervalDuringInterval? makeDough schedule)
          (intervalDuringInterval? sliceOnions schedule)
          (intervalDuringInterval? sliceTomatos schedule)
          (intervalDuringInterval? bakeInOven schedule)
          (intervalDuringInterval? servePizza schedule)
          (intervalDuringInterval? pourWine schedule)
 
          (&amp;lt; 3 (intervalDuration makeDough))
          (&amp;lt; 2 (intervalDuration sliceOnions))
          (&amp;lt; 2 (intervalDuration sliceTomatos))
          (= 35 (intervalDuration bakeInOven))
          (&amp;lt; 2 (intervalDuration servePizza))
          (&amp;lt; 2 (intervalDuration pourWine))
 
          (intervalStartsAfterInterval? bakeInOven makeDough)
          (intervalStartsAfterInterval? bakeInOven sliceOnions)
          (intervalStartsAfterInterval? bakeInOven sliceTomatos)
 
          (intervalStartsAfterInterval? servePizza bakeInOven))
 
(minimize (intervalDuration schedule))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Boom!&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-clojure&#34;&gt;(- (end schedule) (begin schedule)) |-&amp;gt; 46
sat
(model
  (define-fun sliceTomatos () (IntervalT Int Int) (makeInterval 1 4))
  (define-fun pourWine () (IntervalT Int Int) (makeInterval 36 39))
  (define-fun schedule () (IntervalT Int Int) (makeInterval 0 46))
  (define-fun servePizza () (IntervalT Int Int) (makeInterval 42 45))
  (define-fun sliceOnions () (IntervalT Int Int) (makeInterval 1 4))
  (define-fun makeDough () (IntervalT Int Int) (makeInterval 1 5))
  (define-fun bakeInOven () (IntervalT Int Int) (makeInterval 6 41)))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Z3 wants us to make the dough in parallel with slicing tomatos and onions.
We then have to bake the Pizza, and before it is done pour the wine; a few minutes later we serve the Pizza.
Enjoy!&lt;/p&gt;

&lt;p&gt;Note: although this is an optimal schedule we certainly want to improve the constraints, e.g. you want to specify the number of cooks &amp;ndash; but 70 lines of code is a good point to stop with an example.&lt;/p&gt;

&lt;h2 id=&#34;further-remarks:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Further Remarks&lt;/h2&gt;

&lt;p&gt;My notes that can be used with pandoc and pandoc-citeproc are available &lt;a href=&#34;https://gist.github.com/daniel-j-h/09c772b706db7a7240a4&#34;&gt;here&lt;/a&gt;.
The parallel cooking code can be found &lt;a href=&#34;https://gist.github.com/daniel-j-h/09c772b706db7a7240a4#file-9-parallelize-clj&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you are still reading this, &lt;a href=&#34;https://gist.github.com/daniel-j-h/09c772b706db7a7240a4#file-8-layouting-clj&#34;&gt;here&lt;/a&gt; is the promised layouting example including CSS from a solution, which is a bit more elaborate.&lt;/p&gt;

&lt;p&gt;See the official &lt;a href=&#34;http://rise4fun.com/Z3Opt/tutorial/&#34;&gt;nuZ tutorial&lt;/a&gt; for more details.&lt;/p&gt;

&lt;p&gt;Note: beware issues in Z3/nuZ, &lt;a href=&#34;https://github.com/Z3Prover/z3/issues/52&#34;&gt;I reported one&lt;/a&gt; during working on the parallel cooking example.&lt;/p&gt;

&lt;h2 id=&#34;summary:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In preparation for optimizing parallel Pizza cooking you hopefully learnt something about Satisfiability (SAT), Satisfiability Modulo Theories (SMT) and its applications.
We built an interval abstraction and specified constraints about interval durations and dependencies for cooking tasks.
Using Z3&amp;rsquo;s opt branch (nuZ) we then minimized the overall time it takes to cook and serve the Pizza.&lt;/p&gt;

&lt;h2 id=&#34;comment:619ef41b8227f3f88c96d2c07c6ce0b4&#34;&gt;Comment&lt;/h2&gt;

&lt;p&gt;Join the discussion over at &lt;a href=&#34;https://news.ycombinator.com/item?id=9514215&#34;&gt;HackerNews&lt;/a&gt; or Reddit&amp;rsquo;s &lt;a href=&#34;https://www.reddit.com/r/programming/comments/35c04r/satisfiability_modulo_theories_for_parallel/&#34;&gt;/r/programming&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Intuitive Use-Case For Monadic Bind And Kleisli Composition</title>
      <link>https://daniel-j-h.github.io/post/intuitive-monadic-bind-kleisli-composition/</link>
      <pubDate>Fri, 01 May 2015 19:49:27 +0200</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/intuitive-monadic-bind-kleisli-composition/</guid>
      <description>

&lt;p&gt;In which I accidentally stumble upon Monadic Bind and Kleisli Composition while parallelizing my C++14 code with Intel TBB&amp;rsquo;s pipeline. This is meant to help you connecting concepts from various fields rather than diving into too much theory.&lt;/p&gt;

&lt;h2 id=&#34;motivation:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;In my &lt;a href=&#34;https://daniel-j-h.github.io/post/distributed-search-nanomsg-bond/&#34;&gt;post about a Distributed Search Engine&lt;/a&gt; I&amp;rsquo;m using the so called survey communication pattern, which works roughly as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Send request to multiple Respondents&lt;/li&gt;
&lt;li&gt;Gather and merge responses&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In pseudocode with the function&amp;rsquo;s declarations this may look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Blob getMemoryBlobFromNetwork();
Response deserializeBlob(Blob);


ResponseSet responses;

sendSurveyRequest(&amp;quot;Tell me the current time in CEST&amp;quot;);

while not surveyDeadlineReached() {
  Blob blob = getMemoryBlobFromNetwork();
  Response response = deserializeBlob(blob);
  responses.merge(response);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works rather well, but there is room for improvement.
Although the Respondents send their responses concurrently, we handle responses one after the other.
That is we first receive a response as memory blob from the networking layer.
We then deserialize it, after which we merge it into a set of responses.
It is not until then that we turn our attention to the next response.&lt;/p&gt;

&lt;p&gt;Notice how the next function&amp;rsquo;s input depends on the current function&amp;rsquo;s output.
With this kind of dependency the Pipeline Pattern can be easily introduced, with the goal of running the pipeline&amp;rsquo;s stages in parallel, increasing the system&amp;rsquo;s throughput.&lt;/p&gt;

&lt;p&gt;With three responses the pipeline may look as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;      step 1    |     step 2    |     step 3    |     step 4    |     step 5    |
    -----------------------------------------------------------------------------

    receive()   |   receive()   |   receive()   |
                | deserialize() | deserialize() | deserialize() |
                                |    merge()    |    merge()    |    merge()    |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see how we are now able to receive(), deserialize() and merge() potentially in parallel running on multiple threads.&lt;/p&gt;

&lt;p&gt;In the Distributed Search Engine C++14 code this can be accomplished rather easily, using Intel TBB&amp;rsquo;s pipeline. I pushed a &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/commit/97224b179fdc050dc219287616e8d3073e0e0a8c&#34;&gt;commit&lt;/a&gt; with this to the original Distributed Search Engine repository. See &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/97224b179fdc050dc219287616e8d3073e0e0a8c/Service.cc#L110-L114&#34;&gt;the code&lt;/a&gt; for yourself.&lt;/p&gt;

&lt;h2 id=&#34;failures-and-how-to-propagate-them:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Failures And How To Propagate Them&lt;/h2&gt;

&lt;p&gt;Failures happen. We may not be able to deserialize a request.
Maybe we have additional uncompress or decrypt stages that may fail.
But what happens if an exception occurs in a particular pipeline stage? With the above implementation this would bring down the whole pipeline.&lt;/p&gt;

&lt;p&gt;What we really want from our functions is to express a computation that may fail.
That is, instead of the exception throwing functions we want them to wrap their response in something that is able to express failure, such as the generic Optional, also known as Maybe Monad. Here are the declarations with this in mind:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  Optional&amp;lt;Blob&amp;gt; getMemoryBlobFromNetwork();
  Optional&amp;lt;Blob&amp;gt; uncompressBlob(Blob blob);
  Optional&amp;lt;Blob&amp;gt; decryptBlob(Blob blob);
  Optional&amp;lt;Response&amp;gt; deserializeBlob(Blob blob);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect! But wait, now the types do not match!
Our functions do not expect arguments wrapped in an Optional but instead types such as a raw Blob. What we have to do is convert from Optionals to their value type by checking for success and then passing the value type on:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while not surveyDeadlineReached() {
  Optional&amp;lt;Blob&amp;gt; blob0 = getMemoryBlobFromNetwork();
  if (blob0) {
    Optional&amp;lt;Blob&amp;gt; blob1 = decryptBlob(*blob0);

    if (blob1) {
      Optional&amp;lt;Blob&amp;gt; blob2 = uncompressBlob(*blob1);

      if (blob2) {
        Optional&amp;lt;Response&amp;gt; response = deserializeBlob(*blob2);

        if (response) {
          responses.merge(*response);
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is horrible error handling. There has to be a better way. And there is.
Note: you may flatten this kind of error handling with guards, but the overhead remains.&lt;/p&gt;

&lt;p&gt;First let us switch to Haskell for pseudocode as I don&amp;rsquo;t want to show you the C++ that is required for this.
Our dummy functions representing the pipeline stages now take integers and may return an optional of integer, Maybe Integer that is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;-- :: Integer -&amp;gt; Maybe Integer
f0 = \x -&amp;gt; Just (x + 1)
f1 = \x -&amp;gt; Just (x + 10)
f2 = \x -&amp;gt; Just (x + 100)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And a function that always fails, to provoke errors later on:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;-- :: Integer -&amp;gt; Maybe Integer
g0 = \_ -&amp;gt; Nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we still need is a way to convert our functions taking integers to functions taking a Maybe Integer, checking for success, and only then calling the plain function. That is, the type has to be similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;Maybe Integer -&amp;gt; (Integer -&amp;gt; Maybe Integer) -&amp;gt; Maybe Integer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This looks suspiciously similar to what Monadic Bind does. Take a look:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;(&amp;gt;&amp;gt;=) :: m a -&amp;gt; (a -&amp;gt; m b) -&amp;gt; m b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see it in action, using it for passing integers wrapped as Maybe Integer to our functions taking an integer:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;Just 0 &amp;gt;&amp;gt;= f0
Just 1

Just 0 &amp;gt;&amp;gt;= f0 &amp;gt;&amp;gt;= f1 &amp;gt;&amp;gt;= f2
Just 111

Just 0 &amp;gt;&amp;gt;= f0 &amp;gt;&amp;gt;= g0 &amp;gt;&amp;gt;= f1 &amp;gt;&amp;gt;= f2
Nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Monadic Bind for the Maybe monad does exactly what we need:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;in case the passed in Maybe Integer is a Just we go on executing the function on its value&lt;/li&gt;
&lt;li&gt;in case the passed in Maybe Integer is Nothing we do not execute the function but instantaneously return Nothing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is exactly the semantic we want for our motivating pipeline example!&lt;/p&gt;

&lt;h2 id=&#34;composing-propagating-pipeline-stages:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Composing Propagating Pipeline Stages&lt;/h2&gt;

&lt;p&gt;Using Maybe&amp;rsquo;s Monadic Bind as above allows us to adapt our functions without the need for local error handling. Great! But how do we compose a pipeline then?
We could directly use Monadic Bind or think about the types involved.
Say we take two functions and want to compose them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;(Integer -&amp;gt; Maybe Integer) -&amp;gt; (Integer -&amp;gt; Maybe Integer) -&amp;gt; Integer -&amp;gt; Maybe Integer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That is, with two functions and an integer we start off passing the integer to the first function, then doing our Monadic Bind trick from above, potentially passing the result to the second function, returning the result.&lt;/p&gt;

&lt;p&gt;That is what the so called Kleisli composition operator does:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;(&amp;gt;=&amp;gt;) :: (a -&amp;gt; m b) -&amp;gt; (b -&amp;gt; m c) -&amp;gt; a -&amp;gt; m c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Look:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;pipeline = f0 &amp;gt;=&amp;gt; f1 &amp;gt;=&amp;gt; f2
pipeline :: Integer -&amp;gt; Maybe Integer

Just 1 &amp;gt;&amp;gt;= pipeline
Just 112
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Equipped with Monadic Bind and Kleisli Composition we may go back to our C++14 code base and implement the ideas there. I&amp;rsquo;m not going to show you how this can be done here, as it requires some more boilerplate code to make the compiler happy &amp;ndash; as usual.&lt;/p&gt;

&lt;h2 id=&#34;further-remarks:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Further Remarks&lt;/h2&gt;

&lt;p&gt;You probably want to propagate an explanation of what exactly went wrong in case of failure.
This can be done switching out the Maybe Integer for an Either PipelineError Integer, with PipelineError being a sum type of the pipeline stage&amp;rsquo;s potential errors.&lt;/p&gt;

&lt;p&gt;See Scott Wlaschin&amp;rsquo;s slides on monadic bind and what he calls &amp;ldquo;Railway Oriented Programming&amp;rdquo;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/ScottWlaschin/fp-patterns-ndc-london2014&#34;&gt;Functional Programming Patterns (NDC London 2014)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/ScottWlaschin/railway-oriented-programming&#34;&gt;Railway Oriented Programming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more about monads, see Learn You A Haskell &lt;a href=&#34;http://learnyouahaskell.com/chapters&#34;&gt;Chapter 12 and 13&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Haskell documentation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hackage.haskell.org/package/base-4.6.0.1/docs/Control-Monad.html#v:-62--62--61-&#34;&gt;Monadic Bind, &amp;gt;&amp;gt;=&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hackage.haskell.org/package/base-4.6.0.1/docs/Control-Monad.html#v:-62--61--62-&#34;&gt;Kleisli Composition, &amp;gt;=&amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;summary:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In using Monadic Bind and Kleisli Composition we not only composed error propagating pipeline stages, but we did this in a way that keeps the code clean and shows its intention to the reader. Being able to see patterns such as functional composition in code that may look totally unrelated and not in functional style at all &amp;ndash; say C++ in the context of parallelization &amp;ndash; helps tremendously.&lt;/p&gt;

&lt;h2 id=&#34;comment:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Comment&lt;/h2&gt;

&lt;p&gt;Join the discussion over at &lt;a href=&#34;https://news.ycombinator.com/item?id=9477386&#34;&gt;HackerNews&lt;/a&gt;, Reddit&amp;rsquo;s &lt;a href=&#34;http://www.reddit.com/r/programming/comments/34mnqf/an_intuitive_usecase_for_monadic_bind_and_kleisli/&#34;&gt;/r/programming&lt;/a&gt; or &lt;a href=&#34;http://www.reddit.com/r/cpp/comments/34mnqp/an_intuitive_usecase_for_monadic_bind_and_kleisli/&#34;&gt;/r/cpp&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Search Engine with Nanomsg and Bond</title>
      <link>https://daniel-j-h.github.io/post/distributed-search-nanomsg-bond/</link>
      <pubDate>Sun, 22 Mar 2015 13:05:45 +0100</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/distributed-search-nanomsg-bond/</guid>
      <description>

&lt;p&gt;Exploring Microsoft&amp;rsquo;s open source Bond framework by building a distributed search engine.
I&amp;rsquo;m using bond for serialization/deserialization and nanomsg for communication.&lt;/p&gt;

&lt;p&gt;The source for this C++14 project is located at: &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch&#34;&gt;https://github.com/daniel-j-h/DistributedSearch&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;motivation:1b84be3312b0ca180481a342bee08b53&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;A few weeks ago Microsoft open sourced Bond, a cross-platform framework for serialization/deserialization, similar to Google&amp;rsquo;s Protocol Buffers or Cap&amp;rsquo;n Proto. I have some experience with Cap&amp;rsquo;n Proto in particular, so this weekend I wanted to give Bond a try, since I had a few hours to spare.&lt;/p&gt;

&lt;h3 id=&#34;a-distributed-search-engine:1b84be3312b0ca180481a342bee08b53&#34;&gt;A Distributed Search Engine&lt;/h3&gt;

&lt;p&gt;Rob Pike introduced Go&amp;rsquo;s concurrency patterns with an example of a Google-inspired search.
The slides &lt;a href=&#34;https://talks.golang.org/2012/concurrency.slide#42&#34;&gt;are still available&lt;/a&gt; (please quickly skim slides 42-52) and the talk is also on Youtube. Let&amp;rsquo;s pick up this idea and implement it!&lt;/p&gt;

&lt;p&gt;The approach taken is roughly as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Query multiple services concurrently: for web results, video results, news and so on&lt;/li&gt;
&lt;li&gt;Gather the results, merge and show them to the user&lt;/li&gt;
&lt;li&gt;Replicate the services and query the replicas, too&lt;/li&gt;
&lt;li&gt;Do not wait forever, set timeouts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is the general idea. For more information please see the talk mentioned above.&lt;/p&gt;

&lt;p&gt;Now this project consists of the following. The communication part, for sending requests and receiving responses. I&amp;rsquo;m using nanomsg for this.
But first we have to serialize/deserialize our requests, i.e. the keyword to search for and the matches we receive from the services. I&amp;rsquo;m using Bond for this.&lt;/p&gt;

&lt;h2 id=&#34;nanomsg:1b84be3312b0ca180481a342bee08b53&#34;&gt;Nanomsg&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://nanomsg.org/&#34;&gt;nanomsg&lt;/a&gt; is a communication library, designed to provide you with patterns, such as Pub/Sub, Req/Rep, the Survey pattern and more.
You may be familiar with ZeroMQ, nanomsg is more or less the same with a few exceptions. I&amp;rsquo;m using nanomsg since I&amp;rsquo;m already familiar with it.&lt;/p&gt;

&lt;p&gt;Now we design our distributed search engine as follows: a Search service issues user-provided queries concurrently against the WebSearch service, the VideoSearch service and so on. The results are then merged and shown to the user. For this we&amp;rsquo;re using nanomsg&amp;rsquo;s &lt;a href=&#34;http://nanomsg.org/v0.4/nn_survey.7.html&#34;&gt;Survey pattern&lt;/a&gt;.
The Survey pattern sends messages to multiple locations and gathers the responses. For our simple project this is good enough, but having a single Surveyor is not the best idea and you probably want to think about how to factor this into the design.&lt;/p&gt;

&lt;h3 id=&#34;surveyor:1b84be3312b0ca180481a342bee08b53&#34;&gt;Surveyor&lt;/h3&gt;

&lt;p&gt;With the Survey pattern the so called Surveyor (our user-facing Search service) has to &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L28-L37&#34;&gt;bind to the endpoint&lt;/a&gt;, on which so called Respondents connect to.
The Surveyor also sets a timeout after which the survey is over and subsequent results coming in are discarded for this particular survey.&lt;/p&gt;

&lt;p&gt;For every user query the Surveyor now does the following.
Initially &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L57-L58&#34;&gt;broadcast the request to the Respondents&lt;/a&gt;.
Then &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L70&#34;&gt;gather all results from the Respondents&lt;/a&gt; as long as the timeout has not expired.&lt;/p&gt;

&lt;h3 id=&#34;respondents:1b84be3312b0ca180481a342bee08b53&#34;&gt;Respondents&lt;/h3&gt;

&lt;p&gt;Respondents (our WebSearch service, ImageSearch service, and so on) &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L100-L104&#34;&gt;connect to the endpoint&lt;/a&gt;, indicating they want to participate in surveys.
For this the services spin in an eventloop, waiting for requests to process.
Once they &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L121-L122&#34;&gt;receive a request&lt;/a&gt; they handle it (i.e. they search for results) and &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L147-L148&#34;&gt;send matches for this query back&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nohighlight&#34;&gt;
            Surveyor
         bind(localhost)
        /               \
       /                 \
      /                   \
connect(Surveyor)    connect(Surveyor)
   Respondent           Respondent

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the basic communication is set up, let&amp;rsquo;s do the serialization/deserialization part.&lt;/p&gt;

&lt;h2 id=&#34;bond:1b84be3312b0ca180481a342bee08b53&#34;&gt;Bond&lt;/h2&gt;

&lt;p&gt;Using &lt;a href=&#34;https://github.com/Microsoft/bond&#34;&gt;Microsoft&amp;rsquo;s Bond framework&lt;/a&gt;, we&amp;rsquo;re able to serialize and deserialize our messages (i.e. the keyword to search for and the matches we receive) before sending them over the wire.
For this we &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Messages.bond&#34;&gt;define our messages&lt;/a&gt; in a .bond schema.
The bond schema compiler now &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Makefile#L5-L6&#34;&gt;lets us generate stubs&lt;/a&gt; from this schema and they are included in the source repository.
You probably want to augment the messages with more information, such as timestamps, ratings, and so on. For this project a simple schema is good enough.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s interesting now is the fact that the bond compiler is also able to spit out Python and C# stubs, which should make it possible to implement the Surveyor and Respondents in other languages, too. But I did not try this, yet.&lt;/p&gt;

&lt;h3 id=&#34;serialization:1b84be3312b0ca180481a342bee08b53&#34;&gt;Serialization&lt;/h3&gt;

&lt;p&gt;Now what the Surveyor (our user-facing search service) does is to &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L47-L54&#34;&gt;serialize the user-provided keyword&lt;/a&gt; before handing it over to nanomsg.
The Respondents (our WebSearch service, ImageSearch service, and so on) also &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L138-L145&#34;&gt;serialize their results&lt;/a&gt; before sending them back to us.&lt;/p&gt;

&lt;h3 id=&#34;deserialization:1b84be3312b0ca180481a342bee08b53&#34;&gt;Deserialization&lt;/h3&gt;

&lt;p&gt;For every query the Surveyor sends it has to &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L76-L80&#34;&gt;deserialize the responses&lt;/a&gt; nanomsg hands us during the survey.
The respondents similarly have to first &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L129-L133&#34;&gt;deserialize the keyword&lt;/a&gt; the Surveyor sends us.&lt;/p&gt;

&lt;p&gt;The types we used in the schema now integrate perfectly into the language. Therefore &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L82-L83&#34;&gt;merging responses&lt;/a&gt; on the Surveyor side is quite easy, using set semantics. &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L139&#34;&gt;Populating&lt;/a&gt; the data structure with responses on the Respondent&amp;rsquo;s side can be done in the same way.&lt;/p&gt;

&lt;p&gt;Both serialization and deserialization are quite easy with Bond. Especially the (bytes, size)-tuple handling as required when interacting with nanomsg is not as bad as it was with Cap&amp;rsquo;n Proto.
Fortunately Kenton Varda improved the Cap&amp;rsquo;n Proto library in this regard, after &lt;a href=&#34;https://groups.google.com/forum/#!msg/capnproto/viZXnQ5iN50/B-hSgZ1yLWUJ&#34;&gt;a discussion on the mailinglist&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;putting-it-all-together:1b84be3312b0ca180481a342bee08b53&#34;&gt;Putting It All Together&lt;/h2&gt;

&lt;p&gt;With the serialization/deserialization and communication part done, all we have to do is put the pieces together.
That is, wrap what we built and provide a few ways of customization.&lt;/p&gt;

&lt;p&gt;The user-facing Search service &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Search.cc#L10-L20&#34;&gt;interacts with the user and queries the services&lt;/a&gt;.
The search services &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/WebSearch.cc#L9-L20&#34;&gt;wait for queries and handle them&lt;/a&gt; by sending dummy results for now.
Now let&amp;rsquo;s take a look at what we just built!&lt;/p&gt;

&lt;p&gt;Spin up the user-facing Search service and try issuing queries against it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./Search
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Search&amp;gt;
How many horns does a unicorn have?

Results&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No results. Right, we do not have any search service running. Let&amp;rsquo;s spin up a few:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./WebSearch
./VideoSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resulting in the following service tree:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;           Search
          /      \
    WebSearch  VideoSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And interact with the user interface:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Search&amp;gt;
How many horns does a unicorn have?

Results&amp;gt;
 * First Video Result
 * First Web Result
 * Second Video Result
 * Second Web Result
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! We get results back from those two services, without even noticing the connection establishment and communication done in the background during which our program was active at all time.&lt;/p&gt;

&lt;h3 id=&#34;communication-guarantees:1b84be3312b0ca180481a342bee08b53&#34;&gt;Communication Guarantees&lt;/h3&gt;

&lt;p&gt;Now what makes this even more awesome is that nanomsg guarantees us a handful of nice properties.
For example, our user-facing Search service does not care about what services are currently available.
You are also able to disconnect or re-connect any service at any time and the user only sees this in the results available.
This also allows us to start up e.g. multiple WebSearch service replicas in case some are too slow to respond within the timout.
Finally, nanomsg also &lt;a href=&#34;http://nanomsg.org/v0.1/nn_setsockopt.3.html&#34;&gt;handles auto-reconnects&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Furthermore we do not depend on the transport used. Check this out for a local IPC engine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./Search &amp;quot;ipc:///tmp/search.ipc&amp;quot;
./WebSearch &amp;quot;ipc:///tmp/search.ipc&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;recursively-building-service-trees:1b84be3312b0ca180481a342bee08b53&#34;&gt;Recursively Building Service Trees&lt;/h3&gt;

&lt;p&gt;Throughout this project we assumed having a single Surveyor and multiple Respondents attached to it.
But what if a Respondent, e.g. a WebSearch service, has to query multiple WebSearch services recursively itself.
In this case, the Respondent also becomes a Surveyor for its local Respondents. This makes it possible to recursively build a tree of services.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/commit/84c361d336033b5a669b7b37ccc3b0773cb62b54#diff-3&#34;&gt;Introducing&lt;/a&gt; the RecursiveSearch service. The idea is the following: both &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/84c361d336033b5a669b7b37ccc3b0773cb62b54/RecursiveSearch.cc#L10-L11&#34;&gt;bind and connect to endpoints&lt;/a&gt;. The bind endpoint specifies the location Respondents further down the tree have to connect to. The connect endpoint specifies where to send the responses from those Respondents. By &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/84c361d336033b5a669b7b37ccc3b0773cb62b54/RecursiveSearch.cc#L13-L24&#34;&gt;passing on the request&lt;/a&gt; to all attached services we therefore act as a proxy, broadcasting the request to the Respondents attached to us. To guarantee timely delivery of results up the tree, the survey&amp;rsquo;s timeout has to be smaller going down the tree. Leveraging the abstractions built so far makes an implementation possible in only a few lines of code.&lt;/p&gt;

&lt;p&gt;We are now able to recursively build a tree of services:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./Search &amp;quot;tcp://*:9995&amp;quot;
./VideoSearch &amp;quot;tcp://localhost:9995&amp;quot;
./RecursiveSearch &amp;quot;tcp://*:9996&amp;quot; &amp;quot;tcp://localhost:9995&amp;quot;
./WebSearch &amp;quot;tcp://localhost:9996&amp;quot;
./ImageSearch &amp;quot;tcp://localhost:9996&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resulting in the following service tree:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;           Search
          /      \
  VideoSearch   RecursiveSearch
                 /           \
	     WebSearch    ImageSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this setup, Search is the tree&amp;rsquo;s root, with VideoSearch and RecursiveSearch attached to it and WebSearch attached to the RecursiveSearch node. Attaching more services can be done transparently on each layer of the tree. Just attach them to the subtree&amp;rsquo;s specific root-service.&lt;/p&gt;

&lt;p&gt;If you try the recursive example on a single machine, you have to change the port for each layer, otherwise there would be no way to distinguish the root from internal tree nodes. To be more precise, each subtree&amp;rsquo;s root has to bind to a different port.&lt;/p&gt;

&lt;h2 id=&#34;summary:1b84be3312b0ca180481a342bee08b53&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In building a distributed search engine you hopefully learnt something about communication and serialization.
Using nanomsg and its Survey pattern makes the communication part quite easy.
Bond makes the serialization and deserialization part simple to implement.&lt;/p&gt;

&lt;p&gt;The source is hosted on GitHub: &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch&#34;&gt;https://github.com/daniel-j-h/DistributedSearch&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Gentle Introduction To Geospatial Analysis</title>
      <link>https://daniel-j-h.github.io/post/gentle-introduction-postgis/</link>
      <pubDate>Sun, 01 Feb 2015 10:39:49 +0100</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/gentle-introduction-postgis/</guid>
      <description>

&lt;p&gt;This is meant as a gentle introduction into geospatial analysis.&lt;br /&gt;
We&amp;rsquo;re going to use OpenStreetMap datasets and work on PostgreSQL with the PostGIS extension.&lt;/p&gt;

&lt;h2 id=&#34;requirements:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Requirements&lt;/h2&gt;

&lt;p&gt;For our geospatial analysis we need a few packages for importing, querying and exporting the datasets.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;PostgreSQL&lt;/li&gt;
&lt;li&gt;PostGIS&lt;/li&gt;
&lt;li&gt;osm2pgsql&lt;/li&gt;
&lt;li&gt;ogr2ogr&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Install the requirements from your package manager.
For reference: my system is Debian GNU/Linux 8.0 (jessie):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;aptitude install postgresql-9.4 postgis osm2pgsql gdal-bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;preparing-the-database:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Preparing The Database&lt;/h2&gt;

&lt;p&gt;As user postgres (i.e. sudo su postgres) create a new user playground, a new table playground and activate the PostGIS extension:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;createuser playground
createdb --owner playground gis
psql --dbname=gis --command &#39;create extension postgis;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;importing-openstreetmap-datasets:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Importing OpenStreetMap Datasets&lt;/h2&gt;

&lt;p&gt;Geofabrik hosts OpenStreetMap dumps at &lt;a href=&#34;http://download.geofabrik.de&#34;&gt;http://download.geofabrik.de&lt;/a&gt;&lt;br /&gt;
I highly recommend starting with a small dataset first. We&amp;rsquo;re using sweden-latest.osm.pbf here.&lt;/p&gt;

&lt;p&gt;Import the dataset into Postgres. This creates relations and fills the database appropriately for efficient querying:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;osm2pgsql --create --database gis --latlong --slim --cache 4096 --username playground --password --number-processes 4 --multi-geometry --disable-parallel-indexing sweden-latest.osm.pbf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See the osm2pgsql manpage; you may want to change a few parameters e.g. the cache size.&lt;/p&gt;

&lt;p&gt;Hint: this is I/O bound from what I can tell (check iotop, htop), so your cpus won&amp;rsquo;t help much after a few minutes.
In case you don&amp;rsquo;t have a lot of memory you may want to temporarily lower the swappiness before importing:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo sysctl vm.swappiness=10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Warning: importing with the latlong switch means we&amp;rsquo;re using the Spacial Reference System Id 4326 (WGS 84, EPSG:4326), therefore the units are in degree.
We have to cast the geometry type to the geography type if we want to work with meters. Just keep this in mind.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Osm2pgsql&#34;&gt;http://wiki.openstreetmap.org/wiki/Osm2pgsql&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;exporting-query-results-as-geojson:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Exporting Query Results As GeoJSON&lt;/h2&gt;

&lt;p&gt;ogr2ogr is able to issue queries against PostgreSQL, generating GeoJSON&amp;rsquo;s FeatureCollections and inserting your gemometry with description on the fly. See the example exports below for how this can be done. Other formats are available, too.&lt;/p&gt;

&lt;p&gt;If you don&amp;rsquo;t want to use ogr2ogr you have to assemble GeoJSON from primitives such as points and lines yourself.
You&amp;rsquo;re then able to use the exported GeoJSON files as data source e.g. for Mapbox.&lt;/p&gt;

&lt;p&gt;See &lt;a href=&#34;http://www.gdal.org/ogr2ogr.html&#34;&gt;http://www.gdal.org/ogr2ogr.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the following I&amp;rsquo;m using Mapbox for visualization (as long as my data limit is not reached).&lt;/p&gt;

&lt;h2 id=&#34;resources-for-working-on-the-database:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Resources For Working On The Database&lt;/h2&gt;

&lt;p&gt;Here are two good starting points for working on the database.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Database schema: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Osm2pgsql/schema&#34;&gt;http://wiki.openstreetmap.org/wiki/Osm2pgsql/schema&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Map Features: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Map_Features&#34;&gt;http://wiki.openstreetmap.org/wiki/Map_Features&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Scan the Map Features quickly for what is available.
In the following we&amp;rsquo;re doing a few queries against those features.&lt;/p&gt;

&lt;h2 id=&#34;queries-against-features-and-polygons:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Queries Against Features And Polygons&lt;/h2&gt;

&lt;p&gt;Connect to the database:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;psql --dbname=gis --username=playground
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see what kind of relations and columns are available:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;\d
\d planet_osm_point
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Helpful PostGIS functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ST_AsGeoJSON on the geometry returns geojson&lt;/li&gt;
&lt;li&gt;ST_{XMin,YMin} on the geometry returns latlong&lt;/li&gt;
&lt;li&gt;ST_DWithin, ST_Distance and other for filtering and measurements&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See &lt;a href=&#34;http://postgis.net/docs/manual-2.1/reference.html&#34;&gt;http://postgis.net/docs/manual-2.1/reference.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Hints for doing queries:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Limit your query while exploring the dataset, but don&amp;rsquo;t forget to unset the limit for exporting.&lt;/li&gt;
&lt;li&gt;The column&amp;rsquo;s type is text in almost all cases, check for number &amp;lsquo;^[0-9]+$&amp;rsquo; and cast; in order by clauses, too&lt;/li&gt;
&lt;li&gt;use CTRL-A/CTRL+E to jump to the left/right in psql, CTRL+L to clear screen&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now let&amp;rsquo;s do a few queries!&lt;/p&gt;

&lt;h3 id=&#34;all-airports:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;All Airports&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s search for all airports in the dataset.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Scroll through Map Features, find aerialways: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Map_Features#Aerialway&#34;&gt;http://wiki.openstreetmap.org/wiki/Map_Features#Aerialway&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aeroway tag: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Key:aeroway&#34;&gt;http://wiki.openstreetmap.org/wiki/Key:aeroway&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Aerodrome value: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Tag:aeroway%3Daerodrome&#34;&gt;http://wiki.openstreetmap.org/wiki/Tag:aeroway%3Daerodrome&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Warning: aerodrome is strictly speaking not only for airports. There are definitely a few missing, e.g. near Umeå, too.&lt;/p&gt;

&lt;p&gt;Nodes with tags are stored in the planet_osm_point relation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT name,
       ST_AsGeoJSON(way) AS geojson
FROM planet_osm_point
WHERE aeroway=&#39;aerodrome&#39;
ORDER BY name LIMIT 3;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;        name        |                        geojson                         
--------------------+--------------------------------------------------------
 Ålleberg Airport   | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[13.6031192,58.1354088]}
 Älvsbyn Airport    | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[21.0611,65.6456985]}
 Anderstorp Airport | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[13.5993996,57.2641983]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nice! Now we either assemble a GeoJSON document manually from all the rows or we simply use ogr2ogr:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ogr2ogr -f &amp;quot;GeoJSON&amp;quot; airports.geojson -t_srs EPSG:4326 PG:&amp;quot;dbname=&#39;gis&#39; user=&#39;playground&#39; password=&#39;playground&#39;&amp;quot; -s_srs EPSG:4326 -sql &amp;quot;select name, way from planet_osm_point where aeroway=&#39;aerodrome&#39; order by name;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ogr2ogr is quite clever and assembles GeoJSON from your geometries and description itself.&lt;/p&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://a.tiles.mapbox.com/v4/danieljh.l3jbdc17/attribution,zoompan,zoomwheel,geocoder,share.html?access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw&#39;&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;largest-cities:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Largest Cities&lt;/h3&gt;

&lt;p&gt;Now what about the largest cities in the dataset.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Places: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Places&#34;&gt;http://wiki.openstreetmap.org/wiki/Places&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Place tag: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Key:place&#34;&gt;http://wiki.openstreetmap.org/wiki/Key:place&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;City: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Tag:place%3Dcity&#34;&gt;http://wiki.openstreetmap.org/wiki/Tag:place%3Dcity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Population: &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Key:population&#34;&gt;http://wiki.openstreetmap.org/wiki/Key:population&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note: my dataset containes at least one entry where the population field has a value of &amp;ldquo;&amp;gt;50&amp;rdquo;, i.e. not a number.&lt;/p&gt;

&lt;p&gt;Keep this in mind in case you&amp;rsquo;re doing sums, averages or casts in general.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT sum(population::int) AS population
FROM planet_osm_point
WHERE population ~ &#39;^[0-9]+$&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt; population 
------------
  15339409
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hmmm&amp;hellip; interesting. This should be around 9-10 million.&lt;/p&gt;

&lt;p&gt;Now to the largest cities. The &amp;lsquo;city&amp;rsquo; value for the place tag already excludes smaller towns and villages.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT name,
       population::int,
       ST_AsGeoJSON(way) AS geojson
FROM planet_osm_point
WHERE place=&#39;city&#39;
  AND population ~ &#39;^[0-9]+$&#39;
ORDER BY population::int DESC LIMIT 5;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;   name    | population |                        geojson                         
-----------+------------+--------------------------------------------------------
 Stockholm |     829417 | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[18.0710935,59.3251172]}
 Göteborg  |     522259 | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[11.9670171,57.7072326]}
 Malmö     |     303873 | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[13.0001566,55.6052931]}
 Uppsala   |     128400 | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[17.64112,59.8594126]}
 Västerås  |     110877 | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[16.5463679,59.6110992]}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ogr2ogr -f &amp;quot;GeoJSON&amp;quot; cities.geojson -t_srs EPSG:4326 PG:&amp;quot;dbname=&#39;gis&#39; user=&#39;playground&#39; password=&#39;playground&#39;&amp;quot; -s_srs EPSG:4326 -sql &amp;quot;select name, population::int), way from planet_osm_point where place=&#39;city&#39; and population ~ &#39;^[0-9]+\$&#39; order by population::int desc;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://a.tiles.mapbox.com/v4/danieljh.l3jbk96g/attribution,zoompan,zoomwheel,geocoder,share.html?access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw&#39;&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;municipalities:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Municipalities&lt;/h3&gt;

&lt;p&gt;Now we want the city&amp;rsquo;s boundaries e.g. the municipality as polygon.
The relation planet_osm_point only contains nodes with tags.
For the polygon data we have to query the relation planet_osm_polygon in addition.&lt;/p&gt;

&lt;p&gt;To do this, we cross join the nodes with the polygons and filter the largest cities as above.
We also check that our city is inside the municipality polygon.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT polygon.name,
       polygon.way
FROM planet_osm_point AS point
CROSS JOIN planet_osm_polygon AS polygon
WHERE point.place=&#39;city&#39;
  AND polygon.admin_level = &#39;7&#39;
  AND ST_Contains(polygon.way, point.way)
  AND point.population ~ &#39;^[0-9]+$&#39;
ORDER BY point.population::int DESC LIMIT 3;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For admin_level (7 is municipality) see &lt;a href=&#34;http://wiki.openstreetmap.org/wiki/Key:admin_level#admin_level&#34;&gt;http://wiki.openstreetmap.org/wiki/Key:admin_level#admin_level&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The output consists of polygons around the largest cities.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ogr2ogr -f &amp;quot;GeoJSON&amp;quot; boundaries.geojson -t_srs EPSG:4326 PG:&amp;quot;dbname=&#39;gis&#39; user=&#39;playground&#39; password=&#39;playground&#39;&amp;quot; -s_srs EPSG:4326 -sql &amp;quot;select polygon.name, polygon.way from planet_osm_point as point cross join planet_osm_polygon as polygon where point.place=&#39;city&#39; and polygon.admin_level = &#39;7&#39; and ST_Contains(polygon.way, point.way) and point.population ~ &#39;^[0-9]+\$&#39; order by point.population::int desc;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://a.tiles.mapbox.com/v4/danieljh.l3jc1lpa/attribution,zoompan,zoomwheel,geocoder,share.html?access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw&#39;&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;combining-airports-with-largest-cities:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Combining Airports With Largest Cities&lt;/h3&gt;

&lt;p&gt;Now we want all airports that are within a distance X (in kilometers, 50km in this example query) around large cities.&lt;/p&gt;

&lt;p&gt;Warning: we imported with the latlong switch, which means SRID 4326.
Therefore the units are in degrees. We cast to the geography type for working with meters.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s cross join cities with airports and then filter by distance.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT city.name AS city,
       airport.name AS airport_name,
       ST_AsGeoJSON(airport.way) AS airport,
       ST_Distance(city.way::geography, airport.way::geography) AS distance
FROM planet_osm_point AS city
CROSS JOIN planet_osm_point AS airport
WHERE city.place=&#39;city&#39;
  AND city.population ~ &#39;^[0-9]+$&#39;
  AND airport.aeroway=&#39;aerodrome&#39;
  AND ST_DWithin(city.way::geography, airport.way::geography, 50000)
ORDER BY distance LIMIT 3;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    city     |      airport_name      |                        airport                         |    distance    
-------------+------------------------+--------------------------------------------------------+----------------
 Linköping   | Linköping City Airport | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[15.658056,58.4080416]}  | 1970.028258466
 Halmstad    | Halmstad Flygplats     | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[12.8216423,56.6865017]} |   2601.7448687
 Norrköping  | Norrköping Flygplats   | {&amp;quot;type&amp;quot;:&amp;quot;Point&amp;quot;,&amp;quot;coordinates&amp;quot;:[16.2469701,58.5859972]} | 3338.144166465
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ogr2ogr -f &amp;quot;GeoJSON&amp;quot; nearest.geojson -t_srs EPSG:4326 PG:&amp;quot;dbname=&#39;gis&#39; user=&#39;playground&#39; password=&#39;playground&#39;&amp;quot; -s_srs EPSG:4326 -sql &amp;quot;select city.name as city, airport.name as airport_name, airport.way as airport, ST_Distance(city.way::geography, airport.way::geography) as distance from planet_osm_point as city cross join planet_osm_point as airport where city.place=&#39;city&#39; and city.population ~ &#39;^[0-9]+\$&#39; and airport.aeroway=&#39;aerodrome&#39; and ST_DWithin(city.way::geography, airport.way::geography, 50000) order by distance;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://a.tiles.mapbox.com/v4/danieljh.l3jc7m3p/attribution,zoompan,zoomwheel,geocoder,share.html?access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw&#39;&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;combining-geojson:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;Combining GeoJSON&lt;/h3&gt;

&lt;p&gt;Combining GeoJSON is also not a problem.
Municipality polygons and airports around large cities for example.&lt;/p&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://a.tiles.mapbox.com/v4/danieljh.l3jcdofm/attribution,zoompan,zoomwheel,geocoder,share.html?access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw&#39;&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;and-that-s-it:9b8c8843b531f194f39f9a90bfa38bfd&#34;&gt;And That&amp;rsquo;s It&lt;/h3&gt;

&lt;p&gt;This should give you an initial feel for what is possible with geospatial analysis.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>