<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cxx on Daniel J. H.</title>
    <link>https://daniel-j-h.github.io/tags/cxx/</link>
    <description>Recent content in Cxx on Daniel J. H.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Dec 2015 13:53:51 +0100</lastBuildDate>
    <atom:link href="https://daniel-j-h.github.io/tags/cxx/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Selection Algorithms for Graph Partitioning</title>
      <link>https://daniel-j-h.github.io/post/selection-algorithms-for-partitioning/</link>
      <pubDate>Sun, 13 Dec 2015 13:53:51 +0100</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/selection-algorithms-for-partitioning/</guid>
      <description>

&lt;p&gt;In which I optimize a graph partitioner by carefully extracting the algorithm&amp;rsquo;s core requirements and then selecting appropriate C++14 Stdlib algorithms.&lt;/p&gt;

&lt;h2 id=&#34;motivation:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;The following paper introduces a simple yet powerful graph partitioning technique called Inertial Flow.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://sommer.jp/roadseparator.htm&#34;&gt;On Balanced Separators in Road Networks&lt;/a&gt; (doi: &lt;code&gt;10.1007/978-3-319-20086&lt;/code&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The basic idea is this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Sort vertices &amp;ldquo;spatially&amp;rdquo; by a linear combination of their coordinate&amp;rsquo;s latitude and longitude&lt;/li&gt;
&lt;li&gt;Take the first &lt;code&gt;k&lt;/code&gt; nodes forming the sources and the last &lt;code&gt;k&lt;/code&gt; nodes forming the sinks&lt;/li&gt;
&lt;li&gt;Run a single Max-Flow algorithm from sources to sinks and return the corresponding Min-Cut&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Setting the balance parameter &lt;code&gt;k&lt;/code&gt; e.g. to &lt;code&gt;0.25 * |V|&lt;/code&gt; guarantees for a balanced partition, since the disjoint sets have at least &lt;code&gt;k&lt;/code&gt; vertices.
As an optimization you can try different spatial orders, that is visually you rotate a line &lt;code&gt;n&lt;/code&gt; times, run the algorithm and return the best cut.
For partitioning your graph you then recurse on both disjoint vertex sets, until you reach a certain depth or a minimum number of nodes.
That&amp;rsquo;s it. Really, it&amp;rsquo;s that simple and it works surprisingly well!&lt;/p&gt;

&lt;p&gt;Take a look at the following map I generated from dumping the partitioner&amp;rsquo;s graph using &lt;a href=&#34;https://github.com/mapbox/tippecanoe&#34;&gt;tippecanoe&lt;/a&gt; to build  a simplified vector tilesets.&lt;/p&gt;

&lt;iframe width=&#39;100%&#39; height=&#39;500px&#39; frameBorder=&#39;0&#39; src=&#39;https://api.mapbox.com/styles/v1/danieljh/cii4lhkpn005wb8lzwjj43ipy.html?title=true&amp;access_token=pk.eyJ1IjoiZGFuaWVsamgiLCJhIjoiTnNYb25JSSJ9.vYOnsuu1zeKcGW2nj0uJZw#9.658735200693558/52.4992304153767/13.449950544246803/0&#39;&gt;&lt;/iframe&gt;

&lt;p&gt;This is a single algorithm run on Berlin with &lt;code&gt;k = 0.25 * |V|&lt;/code&gt; and a simple spatial order by longitude. The blue points represent the first &lt;code&gt;k&lt;/code&gt; vertices under that spatial order forming the source.
The red points represent the last &lt;code&gt;k&lt;/code&gt; vertices under that spatial order forming the sinks.
Running a single Max-Flow algorithms such as Edmonds–Karp, Push–Relabel or Dinic&amp;rsquo;s algorithm from sources to sinks results in the corresponding Min-Cut that is represented by the black points.&lt;/p&gt;

&lt;h2 id=&#34;deriving-the-spatial-order:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Deriving the Spatial Order&lt;/h2&gt;

&lt;p&gt;The spatial order is derived by a binary function &lt;code&gt;spatially&lt;/code&gt; of two vertices, that compares a linear combination of their coordinate&amp;rsquo;s latitude and longitude.&lt;/p&gt;

&lt;p&gt;The first and last &lt;code&gt;k&lt;/code&gt; vertices can then be determined by using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/sort&#34;&gt;&lt;code&gt;std::sort&lt;/code&gt;&lt;/a&gt; as described in the paper.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sort(begin(vertices), end(vertices), spatially);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then take the first and last &lt;code&gt;k&lt;/code&gt; vertices forming sources and sinks, respectively.
But wait, we can do better: there is no need to sort the vertices in the &amp;ldquo;middle&amp;rdquo;. Let&amp;rsquo;s to less work by using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/partial_sort&#34;&gt;&lt;code&gt;std::partial_sort&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;partial_sort(begin(vertices), begin(vertices) + k, end(vertices), spatially);
partial_sort(rbegin(vertices), rbegin(vertices) + k, rend(vertices), flip(spatially));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This sorts the first &lt;code&gt;k&lt;/code&gt; vertices, and then sorts the last &lt;code&gt;k&lt;/code&gt; vertices with flipped arguments for the binary function (we flip the arguments instead of &lt;code&gt;std::not2&lt;/code&gt; so that the relation is still irreflexive). Great, less work and good enough for our use-case!&lt;/p&gt;

&lt;p&gt;But do we really need a complete ordering of the first and last &lt;code&gt;k&lt;/code&gt; vertices? After all we only need the order to determine sources and sinks for the Max-Flow algorithm.
We are neither interested in which order the first &lt;code&gt;k&lt;/code&gt; are, nor in which order the last &lt;code&gt;k&lt;/code&gt; elements are.
Take a look at the visualization: all what matters is the vertex property &amp;ldquo;first &lt;code&gt;k&lt;/code&gt; in the spatial order&amp;rdquo; (blue) or &amp;ldquo;last &lt;code&gt;k&lt;/code&gt; in the spatial order&amp;rdquo; (red). It does not matter how the red or blue points are ordered in the set of red and blue vertices, respectively.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s give this another try. With &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; we can get the element at position &lt;code&gt;k&lt;/code&gt; that would occur there if the full range was sorted.
In addition, all the elements before the &lt;code&gt;k&lt;/code&gt;th element are &amp;ldquo;less or equal&amp;rdquo; to that element. Interesting, so this is a variation of insertion sort.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nth_element(begin(vertices), begin(vertices) + k, end(vertices), spatially);
nth_element(rbegin(vertices), rbegin(vertices) + k, rend(vertices), flip(spatially));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Visually speaking, this tells us &amp;ldquo;these are red&amp;rdquo;, and &amp;ldquo;these are blue&amp;rdquo;, without any ordering guarantees in the sets.&lt;/p&gt;

&lt;p&gt;It is crucial to understand the difference to partial sorting. Suppose we have a range of integers.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;8 7 6 4 5 3 3 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/partial_sort&#34;&gt;&lt;code&gt;std::partial_sort&lt;/code&gt;&lt;/a&gt; on the first and last three elements results in the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2 3 3 _ _ 6 7 8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In contrast, using &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; on position three from the beginning and end gives you the following guarantees:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_ _ 3 _ _ 6 _ _
____|     |____
&amp;lt;= 3       &amp;gt;= 6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The subranges are no longer sorted, but satisfy the binary function with respect to the selected element. This allows the algorithm to do less work then the partial or even the full sort algorithm.&lt;/p&gt;

&lt;p&gt;Now that we know how &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; works and what guarantees it gives us, we can even go further: the second &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; does not have to take a look at the full range, since we know that we already reordered the first &lt;code&gt;k&lt;/code&gt; elements with the flipped binary function. We therefore come up with the following.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;nth_element(begin(vertices), begin(vertices) + k, end(vertices), spatially);
nth_element(rbegin(vertices), rbegin(vertices) + k, rend(vertices) - k, flip(spatially));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This reorders the first &lt;code&gt;k&lt;/code&gt; elements by looking at the full range and then reorders the last &lt;code&gt;k&lt;/code&gt; elements by only looking at the &lt;code&gt;k + (size - k)&lt;/code&gt; elements from the end.&lt;/p&gt;

&lt;h2 id=&#34;discussion:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Discussion&lt;/h2&gt;

&lt;p&gt;I talked to Christian Sommer, one of the paper&amp;rsquo;s authors, about this. He acknowledged there is no need for a full ordering that &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/sort&#34;&gt;&lt;code&gt;std::sort&lt;/code&gt;&lt;/a&gt; gives you as described in the paper.
Furthermore he argued that you could fully sort your &lt;code&gt;n&lt;/code&gt; spatial orders and keep them around for all recursion steps, which would require more memory and algorithms that can select the subgraph&amp;rsquo;s vertices from the orders.&lt;/p&gt;

&lt;p&gt;As of writing this, the prototype partitioner still uses the Edmonds-Karp algorithms.
We can probably gain significant improvements by using Dinic&amp;rsquo;s algorithm, shadowing the small improvements achieved here.
This does not mean that we should not optimize for easy wins as it was with this case; after all the final reordering optimization on its own is faster than a full sort by a factor of 4-7 from what I saw in a few experiments.
Also, this is where the fun is in engineering and programming :-)&lt;/p&gt;

&lt;h2 id=&#34;further-reading:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Further Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Sean Parent &lt;a href=&#34;https://github.com/sean-parent/sean-parent.github.io/wiki/Papers-and-Presentations&#34;&gt;has a few papers and presentations&lt;/a&gt; in which he explains similar clever Stdlib algorithm usage&lt;/li&gt;
&lt;li&gt;Alexander Stepanov&amp;rsquo;s &amp;ldquo;From Mathematics to Generic Programming&amp;rdquo; and &amp;ldquo;Elements of Programming&amp;rdquo; go in great detail about algorithm requirements and guarantees&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;summary:5db77db6bc73fef476eb5c7187413d9a&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Inertial Flow is a simple yet powerful graph partitioning technique that requires a spatial order.
Deriving the spatial order can be optimized by carefully looking at the algorithm&amp;rsquo;s requirements.
Know your Stdlib, in particular be familiar with more &amp;ldquo;exotic&amp;rdquo; algorithms such as &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/nth_element&#34;&gt;&lt;code&gt;std::nth_element&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;http://en.cppreference.com/w/cpp/algorithm/rotate&#34;&gt;&lt;code&gt;std::rotate&lt;/code&gt;&lt;/a&gt; &amp;mdash; or of course equivalent algorithms in your language of choice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An Intuitive Use-Case For Monadic Bind And Kleisli Composition</title>
      <link>https://daniel-j-h.github.io/post/intuitive-monadic-bind-kleisli-composition/</link>
      <pubDate>Fri, 01 May 2015 19:49:27 +0200</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/intuitive-monadic-bind-kleisli-composition/</guid>
      <description>

&lt;p&gt;In which I accidentally stumble upon Monadic Bind and Kleisli Composition while parallelizing my C++14 code with Intel TBB&amp;rsquo;s pipeline. This is meant to help you connecting concepts from various fields rather than diving into too much theory.&lt;/p&gt;

&lt;h2 id=&#34;motivation:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;In my &lt;a href=&#34;https://daniel-j-h.github.io/post/distributed-search-nanomsg-bond/&#34;&gt;post about a Distributed Search Engine&lt;/a&gt; I&amp;rsquo;m using the so called survey communication pattern, which works roughly as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Send request to multiple Respondents&lt;/li&gt;
&lt;li&gt;Gather and merge responses&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In pseudocode with the function&amp;rsquo;s declarations this may look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Blob getMemoryBlobFromNetwork();
Response deserializeBlob(Blob);


ResponseSet responses;

sendSurveyRequest(&amp;quot;Tell me the current time in CEST&amp;quot;);

while not surveyDeadlineReached() {
  Blob blob = getMemoryBlobFromNetwork();
  Response response = deserializeBlob(blob);
  responses.merge(response);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This works rather well, but there is room for improvement.
Although the Respondents send their responses concurrently, we handle responses one after the other.
That is we first receive a response as memory blob from the networking layer.
We then deserialize it, after which we merge it into a set of responses.
It is not until then that we turn our attention to the next response.&lt;/p&gt;

&lt;p&gt;Notice how the next function&amp;rsquo;s input depends on the current function&amp;rsquo;s output.
With this kind of dependency the Pipeline Pattern can be easily introduced, with the goal of running the pipeline&amp;rsquo;s stages in parallel, increasing the system&amp;rsquo;s throughput.&lt;/p&gt;

&lt;p&gt;With three responses the pipeline may look as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;      step 1    |     step 2    |     step 3    |     step 4    |     step 5    |
    -----------------------------------------------------------------------------

    receive()   |   receive()   |   receive()   |
                | deserialize() | deserialize() | deserialize() |
                                |    merge()    |    merge()    |    merge()    |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see how we are now able to receive(), deserialize() and merge() potentially in parallel running on multiple threads.&lt;/p&gt;

&lt;p&gt;In the Distributed Search Engine C++14 code this can be accomplished rather easily, using Intel TBB&amp;rsquo;s pipeline. I pushed a &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/commit/97224b179fdc050dc219287616e8d3073e0e0a8c&#34;&gt;commit&lt;/a&gt; with this to the original Distributed Search Engine repository. See &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/97224b179fdc050dc219287616e8d3073e0e0a8c/Service.cc#L110-L114&#34;&gt;the code&lt;/a&gt; for yourself.&lt;/p&gt;

&lt;h2 id=&#34;failures-and-how-to-propagate-them:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Failures And How To Propagate Them&lt;/h2&gt;

&lt;p&gt;Failures happen. We may not be able to deserialize a request.
Maybe we have additional uncompress or decrypt stages that may fail.
But what happens if an exception occurs in a particular pipeline stage? With the above implementation this would bring down the whole pipeline.&lt;/p&gt;

&lt;p&gt;What we really want from our functions is to express a computation that may fail.
That is, instead of the exception throwing functions we want them to wrap their response in something that is able to express failure, such as the generic Optional, also known as Maybe Monad. Here are the declarations with this in mind:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  Optional&amp;lt;Blob&amp;gt; getMemoryBlobFromNetwork();
  Optional&amp;lt;Blob&amp;gt; uncompressBlob(Blob blob);
  Optional&amp;lt;Blob&amp;gt; decryptBlob(Blob blob);
  Optional&amp;lt;Response&amp;gt; deserializeBlob(Blob blob);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Perfect! But wait, now the types do not match!
Our functions do not expect arguments wrapped in an Optional but instead types such as a raw Blob. What we have to do is convert from Optionals to their value type by checking for success and then passing the value type on:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;while not surveyDeadlineReached() {
  Optional&amp;lt;Blob&amp;gt; blob0 = getMemoryBlobFromNetwork();
  if (blob0) {
    Optional&amp;lt;Blob&amp;gt; blob1 = decryptBlob(*blob0);

    if (blob1) {
      Optional&amp;lt;Blob&amp;gt; blob2 = uncompressBlob(*blob1);

      if (blob2) {
        Optional&amp;lt;Response&amp;gt; response = deserializeBlob(*blob2);

        if (response) {
          responses.merge(*response);
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is horrible error handling. There has to be a better way. And there is.
Note: you may flatten this kind of error handling with guards, but the overhead remains.&lt;/p&gt;

&lt;p&gt;First let us switch to Haskell for pseudocode as I don&amp;rsquo;t want to show you the C++ that is required for this.
Our dummy functions representing the pipeline stages now take integers and may return an optional of integer, Maybe Integer that is:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;-- :: Integer -&amp;gt; Maybe Integer
f0 = \x -&amp;gt; Just (x + 1)
f1 = \x -&amp;gt; Just (x + 10)
f2 = \x -&amp;gt; Just (x + 100)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And a function that always fails, to provoke errors later on:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;-- :: Integer -&amp;gt; Maybe Integer
g0 = \_ -&amp;gt; Nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What we still need is a way to convert our functions taking integers to functions taking a Maybe Integer, checking for success, and only then calling the plain function. That is, the type has to be similar to:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;Maybe Integer -&amp;gt; (Integer -&amp;gt; Maybe Integer) -&amp;gt; Maybe Integer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This looks suspiciously similar to what Monadic Bind does. Take a look:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;(&amp;gt;&amp;gt;=) :: m a -&amp;gt; (a -&amp;gt; m b) -&amp;gt; m b
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s see it in action, using it for passing integers wrapped as Maybe Integer to our functions taking an integer:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;Just 0 &amp;gt;&amp;gt;= f0
Just 1

Just 0 &amp;gt;&amp;gt;= f0 &amp;gt;&amp;gt;= f1 &amp;gt;&amp;gt;= f2
Just 111

Just 0 &amp;gt;&amp;gt;= f0 &amp;gt;&amp;gt;= g0 &amp;gt;&amp;gt;= f1 &amp;gt;&amp;gt;= f2
Nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Monadic Bind for the Maybe monad does exactly what we need:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;in case the passed in Maybe Integer is a Just we go on executing the function on its value&lt;/li&gt;
&lt;li&gt;in case the passed in Maybe Integer is Nothing we do not execute the function but instantaneously return Nothing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is exactly the semantic we want for our motivating pipeline example!&lt;/p&gt;

&lt;h2 id=&#34;composing-propagating-pipeline-stages:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Composing Propagating Pipeline Stages&lt;/h2&gt;

&lt;p&gt;Using Maybe&amp;rsquo;s Monadic Bind as above allows us to adapt our functions without the need for local error handling. Great! But how do we compose a pipeline then?
We could directly use Monadic Bind or think about the types involved.
Say we take two functions and want to compose them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;(Integer -&amp;gt; Maybe Integer) -&amp;gt; (Integer -&amp;gt; Maybe Integer) -&amp;gt; Integer -&amp;gt; Maybe Integer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That is, with two functions and an integer we start off passing the integer to the first function, then doing our Monadic Bind trick from above, potentially passing the result to the second function, returning the result.&lt;/p&gt;

&lt;p&gt;That is what the so called Kleisli composition operator does:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;(&amp;gt;=&amp;gt;) :: (a -&amp;gt; m b) -&amp;gt; (b -&amp;gt; m c) -&amp;gt; a -&amp;gt; m c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Look:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;pipeline = f0 &amp;gt;=&amp;gt; f1 &amp;gt;=&amp;gt; f2
pipeline :: Integer -&amp;gt; Maybe Integer

Just 1 &amp;gt;&amp;gt;= pipeline
Just 112
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Equipped with Monadic Bind and Kleisli Composition we may go back to our C++14 code base and implement the ideas there. I&amp;rsquo;m not going to show you how this can be done here, as it requires some more boilerplate code to make the compiler happy &amp;ndash; as usual.&lt;/p&gt;

&lt;h2 id=&#34;further-remarks:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Further Remarks&lt;/h2&gt;

&lt;p&gt;You probably want to propagate an explanation of what exactly went wrong in case of failure.
This can be done switching out the Maybe Integer for an Either PipelineError Integer, with PipelineError being a sum type of the pipeline stage&amp;rsquo;s potential errors.&lt;/p&gt;

&lt;p&gt;See Scott Wlaschin&amp;rsquo;s slides on monadic bind and what he calls &amp;ldquo;Railway Oriented Programming&amp;rdquo;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/ScottWlaschin/fp-patterns-ndc-london2014&#34;&gt;Functional Programming Patterns (NDC London 2014)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/ScottWlaschin/railway-oriented-programming&#34;&gt;Railway Oriented Programming&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more about monads, see Learn You A Haskell &lt;a href=&#34;http://learnyouahaskell.com/chapters&#34;&gt;Chapter 12 and 13&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Haskell documentation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hackage.haskell.org/package/base-4.6.0.1/docs/Control-Monad.html#v:-62--62--61-&#34;&gt;Monadic Bind, &amp;gt;&amp;gt;=&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hackage.haskell.org/package/base-4.6.0.1/docs/Control-Monad.html#v:-62--61--62-&#34;&gt;Kleisli Composition, &amp;gt;=&amp;gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;summary:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In using Monadic Bind and Kleisli Composition we not only composed error propagating pipeline stages, but we did this in a way that keeps the code clean and shows its intention to the reader. Being able to see patterns such as functional composition in code that may look totally unrelated and not in functional style at all &amp;ndash; say C++ in the context of parallelization &amp;ndash; helps tremendously.&lt;/p&gt;

&lt;h2 id=&#34;comment:286e9a51e15d74f49bfe6192ec7e59b9&#34;&gt;Comment&lt;/h2&gt;

&lt;p&gt;Join the discussion over at &lt;a href=&#34;https://news.ycombinator.com/item?id=9477386&#34;&gt;HackerNews&lt;/a&gt;, Reddit&amp;rsquo;s &lt;a href=&#34;http://www.reddit.com/r/programming/comments/34mnqf/an_intuitive_usecase_for_monadic_bind_and_kleisli/&#34;&gt;/r/programming&lt;/a&gt; or &lt;a href=&#34;http://www.reddit.com/r/cpp/comments/34mnqp/an_intuitive_usecase_for_monadic_bind_and_kleisli/&#34;&gt;/r/cpp&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Search Engine with Nanomsg and Bond</title>
      <link>https://daniel-j-h.github.io/post/distributed-search-nanomsg-bond/</link>
      <pubDate>Sun, 22 Mar 2015 13:05:45 +0100</pubDate>
      
      <guid>https://daniel-j-h.github.io/post/distributed-search-nanomsg-bond/</guid>
      <description>

&lt;p&gt;Exploring Microsoft&amp;rsquo;s open source Bond framework by building a distributed search engine.
I&amp;rsquo;m using bond for serialization/deserialization and nanomsg for communication.&lt;/p&gt;

&lt;p&gt;The source for this C++14 project is located at: &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch&#34;&gt;https://github.com/daniel-j-h/DistributedSearch&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;motivation:1b84be3312b0ca180481a342bee08b53&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;A few weeks ago Microsoft open sourced Bond, a cross-platform framework for serialization/deserialization, similar to Google&amp;rsquo;s Protocol Buffers or Cap&amp;rsquo;n Proto. I have some experience with Cap&amp;rsquo;n Proto in particular, so this weekend I wanted to give Bond a try, since I had a few hours to spare.&lt;/p&gt;

&lt;h3 id=&#34;a-distributed-search-engine:1b84be3312b0ca180481a342bee08b53&#34;&gt;A Distributed Search Engine&lt;/h3&gt;

&lt;p&gt;Rob Pike introduced Go&amp;rsquo;s concurrency patterns with an example of a Google-inspired search.
The slides &lt;a href=&#34;https://talks.golang.org/2012/concurrency.slide#42&#34;&gt;are still available&lt;/a&gt; (please quickly skim slides 42-52) and the talk is also on Youtube. Let&amp;rsquo;s pick up this idea and implement it!&lt;/p&gt;

&lt;p&gt;The approach taken is roughly as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Query multiple services concurrently: for web results, video results, news and so on&lt;/li&gt;
&lt;li&gt;Gather the results, merge and show them to the user&lt;/li&gt;
&lt;li&gt;Replicate the services and query the replicas, too&lt;/li&gt;
&lt;li&gt;Do not wait forever, set timeouts&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is the general idea. For more information please see the talk mentioned above.&lt;/p&gt;

&lt;p&gt;Now this project consists of the following. The communication part, for sending requests and receiving responses. I&amp;rsquo;m using nanomsg for this.
But first we have to serialize/deserialize our requests, i.e. the keyword to search for and the matches we receive from the services. I&amp;rsquo;m using Bond for this.&lt;/p&gt;

&lt;h2 id=&#34;nanomsg:1b84be3312b0ca180481a342bee08b53&#34;&gt;Nanomsg&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://nanomsg.org/&#34;&gt;nanomsg&lt;/a&gt; is a communication library, designed to provide you with patterns, such as Pub/Sub, Req/Rep, the Survey pattern and more.
You may be familiar with ZeroMQ, nanomsg is more or less the same with a few exceptions. I&amp;rsquo;m using nanomsg since I&amp;rsquo;m already familiar with it.&lt;/p&gt;

&lt;p&gt;Now we design our distributed search engine as follows: a Search service issues user-provided queries concurrently against the WebSearch service, the VideoSearch service and so on. The results are then merged and shown to the user. For this we&amp;rsquo;re using nanomsg&amp;rsquo;s &lt;a href=&#34;http://nanomsg.org/v0.4/nn_survey.7.html&#34;&gt;Survey pattern&lt;/a&gt;.
The Survey pattern sends messages to multiple locations and gathers the responses. For our simple project this is good enough, but having a single Surveyor is not the best idea and you probably want to think about how to factor this into the design.&lt;/p&gt;

&lt;h3 id=&#34;surveyor:1b84be3312b0ca180481a342bee08b53&#34;&gt;Surveyor&lt;/h3&gt;

&lt;p&gt;With the Survey pattern the so called Surveyor (our user-facing Search service) has to &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L28-L37&#34;&gt;bind to the endpoint&lt;/a&gt;, on which so called Respondents connect to.
The Surveyor also sets a timeout after which the survey is over and subsequent results coming in are discarded for this particular survey.&lt;/p&gt;

&lt;p&gt;For every user query the Surveyor now does the following.
Initially &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L57-L58&#34;&gt;broadcast the request to the Respondents&lt;/a&gt;.
Then &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L70&#34;&gt;gather all results from the Respondents&lt;/a&gt; as long as the timeout has not expired.&lt;/p&gt;

&lt;h3 id=&#34;respondents:1b84be3312b0ca180481a342bee08b53&#34;&gt;Respondents&lt;/h3&gt;

&lt;p&gt;Respondents (our WebSearch service, ImageSearch service, and so on) &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L100-L104&#34;&gt;connect to the endpoint&lt;/a&gt;, indicating they want to participate in surveys.
For this the services spin in an eventloop, waiting for requests to process.
Once they &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L121-L122&#34;&gt;receive a request&lt;/a&gt; they handle it (i.e. they search for results) and &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L147-L148&#34;&gt;send matches for this query back&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nohighlight&#34;&gt;
            Surveyor
         bind(localhost)
        /               \
       /                 \
      /                   \
connect(Surveyor)    connect(Surveyor)
   Respondent           Respondent

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that the basic communication is set up, let&amp;rsquo;s do the serialization/deserialization part.&lt;/p&gt;

&lt;h2 id=&#34;bond:1b84be3312b0ca180481a342bee08b53&#34;&gt;Bond&lt;/h2&gt;

&lt;p&gt;Using &lt;a href=&#34;https://github.com/Microsoft/bond&#34;&gt;Microsoft&amp;rsquo;s Bond framework&lt;/a&gt;, we&amp;rsquo;re able to serialize and deserialize our messages (i.e. the keyword to search for and the matches we receive) before sending them over the wire.
For this we &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Messages.bond&#34;&gt;define our messages&lt;/a&gt; in a .bond schema.
The bond schema compiler now &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Makefile#L5-L6&#34;&gt;lets us generate stubs&lt;/a&gt; from this schema and they are included in the source repository.
You probably want to augment the messages with more information, such as timestamps, ratings, and so on. For this project a simple schema is good enough.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s interesting now is the fact that the bond compiler is also able to spit out Python and C# stubs, which should make it possible to implement the Surveyor and Respondents in other languages, too. But I did not try this, yet.&lt;/p&gt;

&lt;h3 id=&#34;serialization:1b84be3312b0ca180481a342bee08b53&#34;&gt;Serialization&lt;/h3&gt;

&lt;p&gt;Now what the Surveyor (our user-facing search service) does is to &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L47-L54&#34;&gt;serialize the user-provided keyword&lt;/a&gt; before handing it over to nanomsg.
The Respondents (our WebSearch service, ImageSearch service, and so on) also &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L138-L145&#34;&gt;serialize their results&lt;/a&gt; before sending them back to us.&lt;/p&gt;

&lt;h3 id=&#34;deserialization:1b84be3312b0ca180481a342bee08b53&#34;&gt;Deserialization&lt;/h3&gt;

&lt;p&gt;For every query the Surveyor sends it has to &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L76-L80&#34;&gt;deserialize the responses&lt;/a&gt; nanomsg hands us during the survey.
The respondents similarly have to first &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L129-L133&#34;&gt;deserialize the keyword&lt;/a&gt; the Surveyor sends us.&lt;/p&gt;

&lt;p&gt;The types we used in the schema now integrate perfectly into the language. Therefore &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L82-L83&#34;&gt;merging responses&lt;/a&gt; on the Surveyor side is quite easy, using set semantics. &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Service.h#L139&#34;&gt;Populating&lt;/a&gt; the data structure with responses on the Respondent&amp;rsquo;s side can be done in the same way.&lt;/p&gt;

&lt;p&gt;Both serialization and deserialization are quite easy with Bond. Especially the (bytes, size)-tuple handling as required when interacting with nanomsg is not as bad as it was with Cap&amp;rsquo;n Proto.
Fortunately Kenton Varda improved the Cap&amp;rsquo;n Proto library in this regard, after &lt;a href=&#34;https://groups.google.com/forum/#!msg/capnproto/viZXnQ5iN50/B-hSgZ1yLWUJ&#34;&gt;a discussion on the mailinglist&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;putting-it-all-together:1b84be3312b0ca180481a342bee08b53&#34;&gt;Putting It All Together&lt;/h2&gt;

&lt;p&gt;With the serialization/deserialization and communication part done, all we have to do is put the pieces together.
That is, wrap what we built and provide a few ways of customization.&lt;/p&gt;

&lt;p&gt;The user-facing Search service &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/Search.cc#L10-L20&#34;&gt;interacts with the user and queries the services&lt;/a&gt;.
The search services &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/62a84caa478b3421e275d57ad0311c879ff89b51/WebSearch.cc#L9-L20&#34;&gt;wait for queries and handle them&lt;/a&gt; by sending dummy results for now.
Now let&amp;rsquo;s take a look at what we just built!&lt;/p&gt;

&lt;p&gt;Spin up the user-facing Search service and try issuing queries against it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./Search
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Search&amp;gt;
How many horns does a unicorn have?

Results&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;No results. Right, we do not have any search service running. Let&amp;rsquo;s spin up a few:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./WebSearch
./VideoSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resulting in the following service tree:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;           Search
          /      \
    WebSearch  VideoSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And interact with the user interface:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Search&amp;gt;
How many horns does a unicorn have?

Results&amp;gt;
 * First Video Result
 * First Web Result
 * Second Video Result
 * Second Web Result
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! We get results back from those two services, without even noticing the connection establishment and communication done in the background during which our program was active at all time.&lt;/p&gt;

&lt;h3 id=&#34;communication-guarantees:1b84be3312b0ca180481a342bee08b53&#34;&gt;Communication Guarantees&lt;/h3&gt;

&lt;p&gt;Now what makes this even more awesome is that nanomsg guarantees us a handful of nice properties.
For example, our user-facing Search service does not care about what services are currently available.
You are also able to disconnect or re-connect any service at any time and the user only sees this in the results available.
This also allows us to start up e.g. multiple WebSearch service replicas in case some are too slow to respond within the timout.
Finally, nanomsg also &lt;a href=&#34;http://nanomsg.org/v0.1/nn_setsockopt.3.html&#34;&gt;handles auto-reconnects&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Furthermore we do not depend on the transport used. Check this out for a local IPC engine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./Search &amp;quot;ipc:///tmp/search.ipc&amp;quot;
./WebSearch &amp;quot;ipc:///tmp/search.ipc&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;recursively-building-service-trees:1b84be3312b0ca180481a342bee08b53&#34;&gt;Recursively Building Service Trees&lt;/h3&gt;

&lt;p&gt;Throughout this project we assumed having a single Surveyor and multiple Respondents attached to it.
But what if a Respondent, e.g. a WebSearch service, has to query multiple WebSearch services recursively itself.
In this case, the Respondent also becomes a Surveyor for its local Respondents. This makes it possible to recursively build a tree of services.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/commit/84c361d336033b5a669b7b37ccc3b0773cb62b54#diff-3&#34;&gt;Introducing&lt;/a&gt; the RecursiveSearch service. The idea is the following: both &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/84c361d336033b5a669b7b37ccc3b0773cb62b54/RecursiveSearch.cc#L10-L11&#34;&gt;bind and connect to endpoints&lt;/a&gt;. The bind endpoint specifies the location Respondents further down the tree have to connect to. The connect endpoint specifies where to send the responses from those Respondents. By &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch/blob/84c361d336033b5a669b7b37ccc3b0773cb62b54/RecursiveSearch.cc#L13-L24&#34;&gt;passing on the request&lt;/a&gt; to all attached services we therefore act as a proxy, broadcasting the request to the Respondents attached to us. To guarantee timely delivery of results up the tree, the survey&amp;rsquo;s timeout has to be smaller going down the tree. Leveraging the abstractions built so far makes an implementation possible in only a few lines of code.&lt;/p&gt;

&lt;p&gt;We are now able to recursively build a tree of services:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./Search &amp;quot;tcp://*:9995&amp;quot;
./VideoSearch &amp;quot;tcp://localhost:9995&amp;quot;
./RecursiveSearch &amp;quot;tcp://*:9996&amp;quot; &amp;quot;tcp://localhost:9995&amp;quot;
./WebSearch &amp;quot;tcp://localhost:9996&amp;quot;
./ImageSearch &amp;quot;tcp://localhost:9996&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Resulting in the following service tree:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;           Search
          /      \
  VideoSearch   RecursiveSearch
                 /           \
	     WebSearch    ImageSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this setup, Search is the tree&amp;rsquo;s root, with VideoSearch and RecursiveSearch attached to it and WebSearch attached to the RecursiveSearch node. Attaching more services can be done transparently on each layer of the tree. Just attach them to the subtree&amp;rsquo;s specific root-service.&lt;/p&gt;

&lt;p&gt;If you try the recursive example on a single machine, you have to change the port for each layer, otherwise there would be no way to distinguish the root from internal tree nodes. To be more precise, each subtree&amp;rsquo;s root has to bind to a different port.&lt;/p&gt;

&lt;h2 id=&#34;summary:1b84be3312b0ca180481a342bee08b53&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In building a distributed search engine you hopefully learnt something about communication and serialization.
Using nanomsg and its Survey pattern makes the communication part quite easy.
Bond makes the serialization and deserialization part simple to implement.&lt;/p&gt;

&lt;p&gt;The source is hosted on GitHub: &lt;a href=&#34;https://github.com/daniel-j-h/DistributedSearch&#34;&gt;https://github.com/daniel-j-h/DistributedSearch&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>